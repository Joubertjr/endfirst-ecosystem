# üóÇÔ∏è Gest√£o de Ontologias no Banco de Refer√™ncias

**Data:** 30 de Dezembro de 2025  
**Objetivo:** Plano completo de gest√£o de ontologias, integrado √† arquitetura atual do projeto

---

## üìã Sum√°rio Executivo

Este documento define como as ontologias ser√£o **estruturadas, versionadas, armazenadas e evolu√≠das** no Banco de Refer√™ncias. A estrat√©gia √© baseada em **metodologia orientada a casos de uso** (Stanford), **modulariza√ß√£o** e **automa√ß√£o** (OntoGPT), seguindo as melhores pr√°ticas identificadas na pesquisa de ontologias.

### Princ√≠pios Fundamentais

1. **Modulariza√ß√£o:** Ontologias divididas em m√≥dulos por dom√≠nio
2. **Versionamento:** Controle de vers√£o expl√≠cito com Git
3. **Automa√ß√£o:** Extra√ß√£o autom√°tica com OntoGPT
4. **Itera√ß√£o:** Evolu√ß√£o baseada em casos de uso
5. **Integra√ß√£o:** Integra√ß√£o cont√≠nua com c√≥digo e banco de dados

---

## üèóÔ∏è 1. Estrutura de Diret√≥rios

### 1.1 Organiza√ß√£o Proposta

```
BANCO_REFERENCIAS/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ontologies/              # NOVO - Ontologias do sistema
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas/             # Schemas LinkML
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base/            # Ontologia base (conceitos fundamentais)
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ document_schema.yaml
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ reference_schema.yaml
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ project_schema.yaml
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ v1/              # Vers√£o 1 (atual)
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ banco_referencias_v1.yaml
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ v2/              # Vers√£o 2 (futuro)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ owl/                 # Ontologias OWL (geradas/importadas)
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.owl
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ banco_referencias.owl
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ repository.py        # Repository para opera√ß√µes de ontologia
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ service.py           # Service para gest√£o de ontologias
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ontology_service.py  # NOVO - Service de ontologias
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ repositories/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ ontology_repository.py  # NOVO - Repository de ontologias
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ tests/
‚îÇ       ‚îî‚îÄ‚îÄ ontologies/              # Testes de ontologias
‚îÇ           ‚îú‚îÄ‚îÄ test_schemas.py
‚îÇ           ‚îî‚îÄ‚îÄ test_ontology_service.py
‚îÇ
‚îú‚îÄ‚îÄ documentacao/
‚îÇ   ‚îî‚îÄ‚îÄ ontologias/                  # NOVO - Documenta√ß√£o de ontologias
‚îÇ       ‚îú‚îÄ‚îÄ README.md                # Vis√£o geral
‚îÇ       ‚îú‚îÄ‚îÄ DECISOES.md              # Decis√µes de modelagem (ADRs)
‚îÇ       ‚îú‚îÄ‚îÄ EVOLUCAO.md              # Hist√≥rico de evolu√ß√£o
‚îÇ       ‚îî‚îÄ‚îÄ GLOSSARIO.md             # Gloss√°rio de termos
‚îÇ
‚îî‚îÄ‚îÄ ontologies/                      # NOVO - Ontologias versionadas (Git)
    ‚îú‚îÄ‚îÄ .gitkeep
    ‚îú‚îÄ‚îÄ README.md
    ‚îú‚îÄ‚îÄ schemas/
    ‚îÇ   ‚îî‚îÄ‚îÄ (schemas LinkML versionados)
    ‚îî‚îÄ‚îÄ owl/
        ‚îî‚îÄ‚îÄ (ontologias OWL versionadas)
```

### 1.2 Justificativa da Estrutura

**Por que duas localiza√ß√µes (`backend/app/ontologies/` e `ontologies/`)?**

1. **`backend/app/ontologies/`** - Ontologias em uso pela aplica√ß√£o
   - Schemas LinkML ativos
   - Ontologias OWL compiladas
   - C√≥digo Python para gest√£o
   - Integra√ß√£o direta com o c√≥digo

2. **`ontologies/`** - Reposit√≥rio versionado de ontologias
   - Hist√≥rico completo de evolu√ß√£o
   - Branching para diferentes vers√µes
   - Documenta√ß√£o de mudan√ßas
   - Backup e controle de vers√£o

**Fluxo:**
```
Ontologias em desenvolvimento ‚Üí ontologies/ (Git)
                                ‚Üì
Ontologias validadas e testadas ‚Üí backend/app/ontologies/ (C√≥digo)
```

---

## üì¶ 2. Arquitetura de Ontologias

### 2.1 Estrutura Modular

**Baseado em:** Metodologia Stanford + Guia T√©cnico de Ontologias

#### M√≥dulo 1: Ontologia Base (Conceitos Fundamentais)

**Arquivo:** `backend/app/ontologies/schemas/base/base_schema.yaml`

```yaml
id: http://banco-referencias.com/ontology/base
name: banco-referencias-base
version: 1.0.0

prefixes:
  linkml: https://w3id.org/linkml/
  br: http://banco-referencias.com/ontology/
  schema: https://schema.org/

default_prefix: br

classes:
  # Classe base para todos os recursos
  Resource:
    description: "Classe base para todos os recursos do sistema"
    attributes:
      id:
        identifier: true
        range: string
      title:
        range: string
        required: true
      description:
        range: string
      created_at:
        range: datetime
      updated_at:
        range: datetime
  
  # Classe para documentos
  Document:
    is_a: Resource
    description: "Documento indexado no sistema"
    attributes:
      filename:
        range: string
        required: true
      file_type:
        range: string
      file_size_bytes:
        range: integer
      google_file_id:
        range: string
        required: true
      status:
        range: DocumentStatus
        default: "active"
    slots:
      - concepts
      - entities
      - references_document
      - belongs_to_project
  
  # Classe para conceitos
  Concept:
    is_a: Resource
    description: "Conceito extra√≠do ou definido no sistema"
    attributes:
      label:
        range: string
        required: true
      definition:
        range: string
      category:
        range: string
    slots:
      - broader
      - narrower
      - related_to
  
  # Classe para entidades
  Entity:
    is_a: Resource
    description: "Entidade nomeada extra√≠da de documentos"
    attributes:
      label:
        range: string
        required: true
      entity_type:
        range: EntityType
        required: true
      confidence:
        range: float
        minimum_value: 0.0
        maximum_value: 1.0
  
  # Classe para refer√™ncias
  Reference:
    is_a: Resource
    description: "Refer√™ncia externa (artigos, papers, etc)"
    attributes:
      category:
        range: string
      subject:
        range: string
      sources:
        range: string
        multivalued: true
    slots:
      - concepts
      - references_reference
  
  # Classe para projetos
  Project:
    is_a: Resource
    description: "Projeto documentado no sistema"
    attributes:
      name:
        range: string
        required: true
      documentation_path:
        range: string
    slots:
      - uses_documents
      - references_project

enums:
  DocumentStatus:
    permissible_values:
      - active
      - archived
      - deleted
  
  EntityType:
    permissible_values:
      - person
      - organization
      - location
      - concept
      - event
      - other

slots:
  # Rela√ß√µes
  concepts:
    description: "Conceitos associados a um recurso"
    range: Concept
    multivalued: true
  
  entities:
    description: "Entidades extra√≠das de um documento"
    range: Entity
    multivalued: true
  
  broader:
    description: "Conceito mais gen√©rico (hierarquia)"
    range: Concept
  
  narrower:
    description: "Conceitos mais espec√≠ficos (hierarquia)"
    range: Concept
    multivalued: true
  
  related_to:
    description: "Conceito relacionado"
    range: Concept
    multivalued: true
  
  references_document:
    description: "Documento referenciado"
    range: Document
    multivalued: true
  
  references_reference:
    description: "Refer√™ncia externa relacionada"
    range: Reference
    multivalued: true
  
  belongs_to_project:
    description: "Projeto ao qual pertence"
    range: Project
  
  uses_documents:
    description: "Documentos usados pelo projeto"
    range: Document
    multivalued: true
  
  references_project:
    description: "Projetos relacionados"
    range: Project
    multivalued: true
```

#### M√≥dulo 2: Ontologia de Documentos

**Arquivo:** `backend/app/ontologies/schemas/document_schema.yaml`

```yaml
id: http://banco-referencias.com/ontology/document
name: banco-referencias-document
version: 1.0.0

imports:
  - base_schema.yaml

classes:
  Document:
    # Estende a classe Document da base
    slots:
      - extracted_entities
      - extracted_relations
      - main_topics
      - keywords
  
  ExtractedEntity:
    is_a: Entity
    attributes:
      source_text:
        range: string
      position:
        range: integer
  
  ExtractedRelation:
    description: "Rela√ß√£o extra√≠da entre entidades"
    attributes:
      subject:
        range: Entity
        required: true
      predicate:
        range: string
        required: true
      object:
        range: Entity
        required: true
      confidence:
        range: float

slots:
  extracted_entities:
    range: ExtractedEntity
    multivalued: true
  
  extracted_relations:
    range: ExtractedRelation
    multivalued: true
  
  main_topics:
    range: Concept
    multivalued: true
  
  keywords:
    range: string
    multivalued: true
```

### 2.2 Estrutura Hier√°rquica de M√≥dulos

```
Ontologia Base (br:base)
‚îú‚îÄ‚îÄ Conceitos Fundamentais (Resource, Concept, Entity)
‚îú‚îÄ‚îÄ Status e Enums
‚îî‚îÄ‚îÄ Rela√ß√µes B√°sicas

Ontologia de Documentos (br:document)
‚îú‚îÄ‚îÄ Extends: br:base
‚îú‚îÄ‚îÄ Document (especializado)
‚îú‚îÄ‚îÄ ExtractedEntity
‚îî‚îÄ‚îÄ ExtractedRelation

Ontologia de Refer√™ncias (br:reference) [Futuro]
‚îú‚îÄ‚îÄ Extends: br:base
‚îî‚îÄ‚îÄ Reference (especializado)

Ontologia de Projetos (br:project) [Futuro]
‚îú‚îÄ‚îÄ Extends: br:base
‚îî‚îÄ‚îÄ Project (especializado)
```

---

## üîÑ 3. Versionamento de Ontologias

### 3.1 Estrat√©gia de Versionamento

**Baseado em:** Semantic Versioning (SemVer) + Git

**Formato:** `MAJOR.MINOR.PATCH`

- **MAJOR:** Mudan√ßas incompat√≠veis (remo√ß√£o de classes, mudan√ßas fundamentais)
- **MINOR:** Novas funcionalidades compat√≠veis (novas classes, propriedades)
- **PATCH:** Corre√ß√µes e melhorias (bugs, refinamentos)

### 3.2 Estrutura de Vers√µes

```
ontologies/
‚îú‚îÄ‚îÄ schemas/
‚îÇ   ‚îú‚îÄ‚îÄ v1.0.0/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_schema.yaml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ document_schema.yaml
‚îÇ   ‚îú‚îÄ‚îÄ v1.1.0/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ (novas features)
‚îÇ   ‚îî‚îÄ‚îÄ v2.0.0/
‚îÇ       ‚îî‚îÄ‚îÄ (mudan√ßas incompat√≠veis)
‚îÇ
‚îî‚îÄ‚îÄ owl/
    ‚îú‚îÄ‚îÄ v1.0.0/
    ‚îÇ   ‚îî‚îÄ‚îÄ banco_referencias_v1.0.0.owl
    ‚îî‚îÄ‚îÄ v2.0.0/
        ‚îî‚îÄ‚îÄ banco_referencias_v2.0.0.owl
```

### 3.3 Processo de Versionamento

**1. Desenvolvimento:**
```bash
# Criar branch para nova vers√£o
git checkout -b feature/ontology-v1.1.0

# Editar schemas em ontologies/schemas/
# Commit
git commit -m "feat(ontology): Adiciona suporte a keywords em documentos"
```

**2. Valida√ß√£o:**
```bash
# Validar schema LinkML
linkml-validate schemas/v1.1.0/document_schema.yaml

# Gerar OWL
linkml-gen-owl schemas/v1.1.0/document_schema.yaml -o owl/v1.1.0/banco_referencias.owl

# Testes
pytest tests/ontologies/
```

**3. Release:**
```bash
# Tag da vers√£o
git tag -a v1.1.0 -m "Ontologia v1.1.0: Suporte a keywords"

# Copiar para backend/app/ontologies/ (vers√£o ativa)
cp -r ontologies/schemas/v1.1.0/* backend/app/ontologies/schemas/v1/
cp -r ontologies/owl/v1.1.0/* backend/app/ontologies/owl/
```

**4. Documenta√ß√£o:**
- Atualizar `documentacao/ontologias/EVOLUCAO.md`
- Documentar mudan√ßas em `documentacao/ontologias/DECISOES.md`

### 3.4 Migra√ß√£o entre Vers√µes

**Estrat√©gia:** Compatibilidade retroativa quando poss√≠vel

```python
# backend/app/services/ontology_migration_service.py
class OntologyMigrationService:
    """Service para migra√ß√£o entre vers√µes de ontologia."""
    
    async def migrate_data(
        self, 
        data: dict, 
        from_version: str, 
        to_version: str
    ) -> dict:
        """
        Migra dados de uma vers√£o para outra.
        
        Args:
            data: Dados na vers√£o antiga
            from_version: Vers√£o de origem (ex: "1.0.0")
            to_version: Vers√£o de destino (ex: "1.1.0")
            
        Returns:
            Dados na nova vers√£o
        """
        # L√≥gica de migra√ß√£o baseada em regras
        if from_version == "1.0.0" and to_version == "1.1.0":
            # Adicionar campos novos com valores padr√£o
            if "keywords" not in data:
                data["keywords"] = []
            return data
        
        # ... outras migra√ß√µes
```

---

## üîß 4. Armazenamento e Persist√™ncia

### 4.1 Onde Armazenar Ontologias

**1. Schemas LinkML (Fonte):**
- **Localiza√ß√£o:** `backend/app/ontologies/schemas/`
- **Formato:** YAML
- **Uso:** Fonte de verdade, usado por OntoGPT

**2. Ontologias OWL (Compiladas):**
- **Localiza√ß√£o:** `backend/app/ontologies/owl/`
- **Formato:** OWL/RDF
- **Uso:** Queries SPARQL, reasoners, integra√ß√£o com sistemas externos

**3. Knowledge Graph (Inst√¢ncias):**
- **Localiza√ß√£o:** Neo4j (Knowledge Graph Database)
- **Formato:** Grafo de n√≥s e arestas
- **Uso:** Queries Cypher, buscas relacionais

**4. PostgreSQL (Metadata):**
- **Localiza√ß√£o:** Tabelas `documents`, `references`, `projects`
- **Formato:** JSONB (campos `metadata`, `concepts`, `entities`)
- **Uso:** Queries SQL, backup, relat√≥rios

### 4.2 Modelo de Dados H√≠brido com Sincroniza√ß√£o Resiliente

> **‚ö†Ô∏è Cr√≠tica Cr√≠tica Aplicada:** Implementa padr√£o Outbox/Saga para garantir consist√™ncia eventual e resili√™ncia em ambiente distribu√≠do.

**Arquitetura com Padr√£o Outbox:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Schemas LinkML (YAML)           ‚îÇ
‚îÇ  (Fonte de verdade, versionado em Git)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ
                ‚îÇ Compila√ß√£o
                ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      Ontologias OWL (RDF/Turtle)        ‚îÇ
‚îÇ     (Para integra√ß√£o e queries SPARQL)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ
                ‚îÇ Instancia√ß√£o
                ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      PostgreSQL (Fonte de Verdade)      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ Documents, References, Projects  ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ ontology_outbox (NOVO) ‚≠ê        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ - Eventos para sincroniza√ß√£o     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ - Transa√ß√£o at√¥mica com dados    ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ
                ‚îÇ Worker Ass√≠ncrono (Celery/RQ)
                ‚îÇ (Sincroniza√ß√£o Idempotente)
                ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Knowledge Graph (Neo4j)         ‚îÇ
‚îÇ    (Inst√¢ncias: entidades e rela√ß√µes)   ‚îÇ
‚îÇ    (Consist√™ncia Eventual)              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Por Que Outbox Pattern?**

- ‚úÖ **Atomicidade:** Eventos criados na mesma transa√ß√£o dos dados
- ‚úÖ **Resili√™ncia:** Se Neo4j estiver fora, sistema continua funcionando
- ‚úÖ **Idempot√™ncia:** Worker pode reprocessar eventos sem duplicar dados
- ‚úÖ **Rastreabilidade:** Hist√≥rico completo de sincroniza√ß√µes
- ‚úÖ **Desacoplamento:** L√≥gica de neg√≥cio separada da sincroniza√ß√£o

**Modelo de Outbox:**

```python
# backend/app/models/ontology_outbox.py
from sqlalchemy import Column, String, Text, DateTime, JSON, Boolean, Integer
from sqlalchemy.dialects.postgresql import UUID
from sqlalchemy.sql import func
import uuid
import json

class OntologyOutboxEvent(Base):
    """Eventos para sincroniza√ß√£o com Knowledge Graph."""
    
    __tablename__ = "ontology_outbox"
    
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    event_type = Column(String(100), nullable=False, index=True)
    # Tipos: DOCUMENT_ONTOLOGY_UPDATED, DOCUMENT_DELETED, ENTITY_RESOLVED, etc.
    
    aggregate_id = Column(UUID(as_uuid=True), nullable=False, index=True)  # document_id, etc
    aggregate_type = Column(String(50), nullable=False)  # "document", "reference", etc
    
    payload = Column(JSON, nullable=False)  # Dados do evento
    
    processed = Column(Boolean, default=False, nullable=False, index=True)
    processed_at = Column(DateTime(timezone=True), nullable=True)
    retry_count = Column(Integer, default=0, nullable=False)
    error_message = Column(Text, nullable=True)
    
    created_at = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)
    
    def __repr__(self) -> str:
        return f"<OntologyOutboxEvent(id={self.id}, event_type='{self.event_type}', processed={self.processed})>"
```

**Service Refatorado com Outbox:**

```python
# backend/app/services/ontology_service.py
class OntologyService:
    """Service para gest√£o de ontologias com sincroniza√ß√£o resiliente."""
    
    def __init__(self, db: AsyncSession):
        self.db = db
        self.extraction_service = KnowledgeExtractionService()
        self.outbox_repository = OutboxRepository(db)
        self.document_repository = DocumentRepository(db)
    
    async def process_document_ontology(
        self, 
        document_id: UUID,
        document_content: str
    ) -> ProcessedOntology:
        """
        Processa ontologia de um documento usando padr√£o Outbox.
        
        A opera√ß√£o √© at√¥mica no PostgreSQL. Sincroniza√ß√£o com Neo4j
        ocorre de forma ass√≠ncrona via worker.
        """
        async with self.db.begin() as session:
            # 1. Extrair conhecimento
            extracted = await self.extraction_service.extract_from_document(
                document_content
            )
            
            # 2. Validar (poderia ter EntityResolutionService aqui)
            validated = await self._validate_knowledge(extracted)
            
            # 3. Atualizar documento no PostgreSQL (FONTE DE VERDADE)
            await self.document_repository.update_ontology_fields(
                document_id=document_id,
                concepts=validated.concepts,
                entities=validated.entities,
                relations=validated.relations,
                ontology_version="1.0.0"
            )
            
            # 4. Criar evento na outbox (MESMA TRANSA√á√ÉO)
            await self.outbox_repository.create_event(
                event_type="DOCUMENT_ONTOLOGY_UPDATED",
                aggregate_id=document_id,
                aggregate_type="document",
                payload={
                    "document_id": str(document_id),
                    "entities": [e.dict() for e in validated.entities],
                    "concepts": [c.dict() for c in validated.concepts],
                    "relations": [r.dict() for r in validated.relations],
                }
            )
            # Commit da transa√ß√£o (at√¥mico: dados + evento)
        
        # Retorna resultado (Neo4j ser√° atualizado assincronamente)
        return ProcessedOntology(
            document_id=document_id,
            entities=validated.entities,
            concepts=validated.concepts,
            relations=validated.relations,
            sync_status="pending"  # Status da sincroniza√ß√£o
        )
```

**Worker de Sincroniza√ß√£o:**

```python
# backend/app/workers/neo4j_sync_worker.py
from celery import Celery
import logging

logger = logging.getLogger(__name__)

app = Celery('neo4j_sync')

@app.task(bind=True, max_retries=3)
def sync_neo4j_from_outbox(self):
    """
    Worker que sincroniza eventos da outbox com Neo4j.
    
    Executa de forma idempotente e resiliente a falhas.
    """
    from app.core.database import AsyncSessionLocal
    from app.repositories.ontology_outbox_repository import OutboxRepository
    from app.repositories.knowledge_graph_repository import KnowledgeGraphRepository
    
    db = AsyncSessionLocal()
    outbox_repo = OutboxRepository(db)
    kg_repo = KnowledgeGraphRepository()
    
    try:
        # Buscar eventos n√£o processados
        events = await outbox_repo.get_unprocessed_events(limit=100)
        
        for event in events:
            try:
                # Aplicar mudan√ßa no Neo4j (idempotente)
                await kg_repo.apply_event(event)
                
                # Marcar como processado
                await outbox_repo.mark_as_processed(event.id)
                logger.info(f"Event {event.id} synced to Neo4j successfully")
                
            except Exception as e:
                # Incrementar retry count
                await outbox_repo.increment_retry(event.id, str(e))
                logger.error(f"Failed to sync event {event.id}: {e}", exc_info=True)
                
                # Se exceder m√°ximo de retries, marcar para revis√£o manual
                if event.retry_count >= 3:
                    logger.critical(
                        f"Event {event.id} exceeded max retries. Requires manual review.",
                        extra={"event_id": str(event.id), "error": str(e)}
                    )
        
        await db.commit()
        
    except Exception as e:
        await db.rollback()
        logger.error(f"Error in sync worker: {e}", exc_info=True)
        raise self.retry(exc=e, countdown=60)  # Retry em 60 segundos
    
    finally:
        await db.close()

# Configurar para rodar a cada 5 segundos
app.conf.beat_schedule = {
    'sync-neo4j-outbox': {
        'task': 'neo4j_sync_worker.sync_neo4j_from_outbox',
        'schedule': 5.0,
    },
}
```

**Fonte da Verdade para Leitura:**

```python
# Estrat√©gia de leitura h√≠brida
class HybridReadStrategy:
    """
    Define de onde ler dados baseado no tipo de query.
    
    PostgreSQL = Fonte de verdade para metadata e dados transacionais
    Neo4j = Fonte de verdade para rela√ß√µes e queries de grafo
    """
    
    async def get_document_with_ontology(self, document_id: UUID) -> DocumentWithOntology:
        """
        Busca documento com ontologia.
        
        - Metadata e campos b√°sicos: PostgreSQL (fonte de verdade)
        - Rela√ß√µes e entidades relacionadas: Neo4j (se dispon√≠vel)
        """
        # 1. Buscar metadata do PostgreSQL (sempre)
        document = await document_repository.get_by_id(document_id)
        
        # 2. Tentar buscar rela√ß√µes do Neo4j (opcional, degrada graciosamente)
        try:
            related_entities = await kg_repository.get_related_entities(document_id)
            document.related_entities = related_entities
        except Exception as e:
            logger.warning(f"Could not fetch relations from Neo4j: {e}")
            document.related_entities = []  # Degrada graciosamente
        
        return document
```

**Benef√≠cios da Arquitetura Outbox:**

- ‚úÖ **Resili√™ncia:** Sistema continua funcionando se Neo4j estiver fora
- ‚úÖ **Consist√™ncia Eventual:** Dados eventualmente ficam consistentes
- ‚úÖ **Rastreabilidade:** Hist√≥rico completo de sincroniza√ß√µes
- ‚úÖ **Idempot√™ncia:** Reprocessamento seguro de eventos
- ‚úÖ **Desacoplamento:** L√≥gica de neg√≥cio independente da sincroniza√ß√£o

### 4.3 Integra√ß√£o com Models Existentes

**Expandir models SQLAlchemy com campos de ontologia:**

```python
# backend/app/models/document.py
class Document(Base):
    """Model de documento com suporte a ontologias."""
    
    # ... campos existentes ...
    
    # Campos de ontologia (NOVO)
    concepts = Column(JSON, nullable=True)  # Lista de conceitos
    entities = Column(JSON, nullable=True)  # Entidades extra√≠das
    relations = Column(JSON, nullable=True)  # Rela√ß√µes extra√≠das
    ontology_version = Column(String(20), default="1.0.0")  # Vers√£o da ontologia usada
    extracted_at = Column(DateTime(timezone=True), nullable=True)  # Quando foi extra√≠do
```

---

## üöÄ 5. Processo de Evolu√ß√£o

### 5.1 Ciclo de Vida da Ontologia

**Baseado em:** Metodologia Stanford + Best Practices

```
1. Defini√ß√£o de Caso de Uso
   ‚Üì
2. Cria√ß√£o/Atualiza√ß√£o de Schema LinkML
   ‚Üì
3. Valida√ß√£o (linkml-validate)
   ‚Üì
4. Extra√ß√£o com OntoGPT (teste)
   ‚Üì
5. Revis√£o e Refinamento (humano)
   ‚Üì
6. Compila√ß√£o para OWL
   ‚Üì
7. Testes (unit√°rios + integra√ß√£o)
   ‚Üì
8. Versionamento (Git tag)
   ‚Üì
9. Deploy (copiar para app/ontologies/)
   ‚Üì
10. Migra√ß√£o de Dados (se necess√°rio)
    ‚Üì
11. Monitoramento e Feedback
    ‚Üì
12. Pr√≥xima itera√ß√£o
```

### 5.2 Perguntas de Compet√™ncia

> **Melhoria de Valida√ß√£o:** Conectar perguntas de compet√™ncia a testes automatizados para valida√ß√£o cont√≠nua.

**Documentar perguntas que a ontologia deve responder:**

```markdown
# documentacao/ontologias/COMPETENCY_QUESTIONS.md

## Perguntas de Compet√™ncia v1.0.0

### Documentos
1. Quais documentos cont√™m este conceito?
2. Quais s√£o as entidades principais de um documento?
3. Quais documentos est√£o relacionados semanticamente?
4. Quais conceitos s√£o mencionados neste documento?

### Refer√™ncias
5. Quais refer√™ncias citam este documento?
6. Quais refer√™ncias s√£o sobre este assunto?
7. Quais conceitos est√£o associados a esta refer√™ncia?

### Projetos
8. Quais documentos pertencem a este projeto?
9. Quais projetos usam esta refer√™ncia?
10. Quais s√£o os conceitos principais deste projeto?
```

**Testes Automatizados para Perguntas de Compet√™ncia:**

```python
# backend/tests/ontologies/test_competency.py
import pytest
from uuid import UUID

@pytest.mark.asyncio
async def test_cq_01_find_documents_by_concept(ontology_service, test_kg_data):
    """
    Testa a Pergunta de Compet√™ncia 1: Quais documentos cont√™m este conceito?
    
    Arrange: Popula o KG com dados de teste
    Act: Executa a query
    Assert: Verifica o resultado
    """
    # Arrange: Popula o KG com dados de teste
    await populate_kg_with_test_data(test_kg_data)
    
    # Act: Executa a query
    concept = "Intelig√™ncia Artificial"
    documents = await ontology_service.find_documents_by_concept(concept)
    
    # Assert: Verifica o resultado
    assert len(documents) >= 2, "Deveria encontrar pelo menos 2 documentos"
    assert any("IA" in d.title or "Artificial Intelligence" in d.title for d in documents), \
        "Deveria encontrar documentos relacionados"

@pytest.mark.asyncio
async def test_cq_02_find_main_entities_in_document(ontology_service, test_kg_data):
    """Testa CQ 2: Quais s√£o as entidades principais de um documento?"""
    document_id = UUID("123e4567-e89b-12d3-a456-426614174000")
    
    entities = await ontology_service.find_main_entities_in_document(document_id)
    
    assert len(entities) > 0, "Deveria encontrar pelo menos uma entidade"
    # Verificar que entidades t√™m confian√ßa acima do threshold
    assert all(e.confidence >= 0.7 for e in entities), \
        "Entidades principais devem ter confian√ßa >= 0.7"

@pytest.mark.asyncio
async def test_cq_03_find_semantically_related_documents(ontology_service, test_kg_data):
    """Testa CQ 3: Quais documentos est√£o relacionados semanticamente?"""
    document_id = UUID("123e4567-e89b-12d3-a456-426614174001")
    
    related_docs = await ontology_service.find_semantically_related_documents(
        document_id,
        min_similarity=0.8
    )
    
    assert len(related_docs) >= 1, "Deveria encontrar pelo menos um documento relacionado"
    assert all(doc.similarity_score >= 0.8 for doc in related_docs), \
        "Documentos relacionados devem ter similaridade >= 0.8"

# ... mais testes para outras perguntas de compet√™ncia
```

**Benef√≠cios:**
- ‚úÖ **Regress√£o Automatizada:** Garante que novas vers√µes da ontologia n√£o quebrem funcionalidades existentes
- ‚úÖ **Documenta√ß√£o Viva:** Os testes se tornam a prova execut√°vel de que a ontologia funciona como esperado
- ‚úÖ **CI/CD Integration:** Testes rodam automaticamente em cada PR

### 5.3 Processo de Refinamento

**Baseado em:** Stanford Ontology 101

1. **Come√ßar Simples:**
   - Schema m√≠nimo necess√°rio para casos de uso
   - Adicionar complexidade gradualmente

2. **Validar Continuamente:**
   - Testar contra perguntas de compet√™ncia
   - Validar com dados reais
   - Obter feedback de usu√°rios

3. **Iterar:**
   - Adicionar classes/propriedades conforme necess√°rio
   - Refinar baseado em uso real
   - Documentar decis√µes

---

## ü§ñ 6. Automa√ß√£o e Ferramentas

### 6.1 Integra√ß√£o com OntoGPT (com Estrat√©gia de Fallback)

**Service de Extra√ß√£o com Fallback:**

> **Melhoria de Robustez:** Implementa estrat√©gia de fallback usando spaCy quando OntoGPT falha, garantindo alta disponibilidade do sistema.

```python
# backend/app/services/knowledge_extraction_service.py
import spacy
from ontogpt import extract
from pathlib import Path
import logging

logger = logging.getLogger(__name__)

class KnowledgeExtractionService:
    """Service para extra√ß√£o de conhecimento usando OntoGPT com fallback para spaCy."""
    
    def __init__(self):
        self.schema_path = Path(__file__).parent.parent / "ontologies" / "schemas" / "v1" / "document_schema.yaml"
        # Carregar modelo spaCy para fallback
        try:
            self.nlp = spacy.load("en_core_web_sm")
        except OSError:
            logger.warning("spaCy model 'en_core_web_sm' not found. Install with: python -m spacy download en_core_web_sm")
            self.nlp = None
    
    async def extract_from_document(
        self, 
        document_content: str
    ) -> ExtractedKnowledge:
        """
        Extrai conhecimento estruturado usando OntoGPT com fallback para spaCy.
        
        Args:
            document_content: Conte√∫do do documento (texto)
            
        Returns:
            ExtractedKnowledge com entidades, conceitos e rela√ß√µes
        """
        try:
            # Tenta a extra√ß√£o prim√°ria com OntoGPT
            result = extract(
                input_text=document_content,
                template="Document",
                schema=str(self.schema_path)
            )
            
            # Adicionar verifica√ß√£o de confian√ßa, se dispon√≠vel
            # if hasattr(result, 'confidence') and result.confidence < 0.7:
            #     raise ValueError("Low confidence extraction")
            
            return ExtractedKnowledge(
                entities=result.extracted_object.get("entities", []),
                concepts=result.extracted_object.get("concepts", []),
                relations=result.extracted_object.get("extracted_relations", []),
                extraction_method="ontogpt"
            )
        except Exception as e:
            logger.error(f"OntoGPT extraction failed: {e}. Using fallback.", exc_info=True)
            return await self._fallback_extraction(document_content)
    
    async def _fallback_extraction(self, document_content: str) -> ExtractedKnowledge:
        """
        Extra√ß√£o de fallback usando spaCy para entidades b√°sicas.
        
        Retorna apenas entidades nomeadas (NER), sem conceitos ou rela√ß√µes complexas.
        """
        if not self.nlp:
            logger.error("Fallback extraction unavailable: spaCy model not loaded")
            return ExtractedKnowledge(entities=[], concepts=[], relations=[], extraction_method="none")
        
        doc = self.nlp(document_content)
        entities = []
        
        for ent in doc.ents:
            entities.append(Entity(
                label=ent.text,
                entity_type=ent.label_.lower(),  # Normalizar labels
                confidence=1.0  # spaCy n√£o retorna confian√ßa, usar 1.0 como padr√£o
            ))
        
        logger.info(f"Fallback extraction completed: {len(entities)} entities found")
        
        # Retorna apenas entidades, sem conceitos ou rela√ß√µes complexas
        return ExtractedKnowledge(
            entities=entities,
            concepts=[],
            relations=[],
            extraction_method="spacy_fallback"
        )
```

**Benef√≠cios:**
- ‚úÖ **Alta Disponibilidade:** O enriquecimento de documentos n√£o para se a API externa falhar
- ‚úÖ **Degrada√ß√£o Graciosa:** O sistema continua a extrair valor (entidades b√°sicas) mesmo em modo de falha
- ‚úÖ **Resili√™ncia:** Sistema robusto para opera√ß√£o em produ√ß√£o

### 6.2 Compila√ß√£o Autom√°tica

**Script de Build:**

```python
# backend/scripts/build_ontologies.py
"""Script para compilar ontologias LinkML para OWL."""

import subprocess
from pathlib import Path

def build_ontologies():
    """Compila schemas LinkML para OWL."""
    schemas_dir = Path("app/ontologies/schemas/v1")
    owl_dir = Path("app/ontologies/owl")
    
    for schema_file in schemas_dir.glob("*.yaml"):
        owl_file = owl_dir / f"{schema_file.stem}.owl"
        
        # Compilar usando linkml-gen-owl
        subprocess.run([
            "linkml-gen-owl",
            str(schema_file),
            "-o", str(owl_file)
        ])
        
        print(f"‚úÖ Compilado: {schema_file} -> {owl_file}")

if __name__ == "__main__":
    build_ontologies()
```

### 6.3 Valida√ß√£o Autom√°tica

**Tests de Ontologia:**

```python
# backend/tests/ontologies/test_schemas.py
import pytest
from linkml.validators import JsonSchemaDataValidator
from pathlib import Path

class TestOntologySchemas:
    """Testes de valida√ß√£o de schemas de ontologia."""
    
    def test_base_schema_valid(self):
        """Testa se o schema base √© v√°lido."""
        schema_path = Path("app/ontologies/schemas/v1/base_schema.yaml")
        validator = JsonSchemaDataValidator(schema_path)
        # Schema deve ser v√°lido
        assert validator is not None
    
    def test_document_schema_valid(self):
        """Testa se o schema de documentos √© v√°lido."""
        schema_path = Path("app/ontologies/schemas/v1/document_schema.yaml")
        validator = JsonSchemaDataValidator(schema_path)
        assert validator is not None
    
    def test_schema_consistency(self):
        """Testa consist√™ncia entre schemas."""
        # Validar que imports funcionam
        # Validar que classes referenciadas existem
        pass
```

### 6.4 Resolu√ß√£o e Deduplica√ß√£o de Entidades

> **Melhoria de Qualidade:** Implementa deduplica√ß√£o usando embeddings de similaridade para manter o Knowledge Graph limpo e conectado.

**Service de Resolu√ß√£o de Entidades:**

```python
# backend/app/services/entity_resolution_service.py
from sentence_transformers import SentenceTransformer
import logging

logger = logging.getLogger(__name__)

class EntityResolutionService:
    """Service para resolu√ß√£o e deduplica√ß√£o de entidades usando embeddings."""
    
    def __init__(self, kg_repository: 'KnowledgeGraphRepository'):
        """
        Inicializa o service de resolu√ß√£o de entidades.
        
        Args:
            kg_repository: Repository para acessar o Knowledge Graph
        """
        self.model = SentenceTransformer('all-MiniLM-L6-v2')  # Modelo leve e r√°pido
        self.kg_repository = kg_repository
        self.similarity_threshold = 0.95  # Threshold para considerar entidades similares
    
    async def resolve_entity(self, entity: Entity) -> Entity:
        """
        Encontra ou cria uma entidade can√¥nica no KG.
        
        Usa busca por similaridade sem√¢ntica para evitar duplicatas.
        
        Args:
            entity: Entidade a ser resolvida
            
        Returns:
            Entity can√¥nica (existente ou criada)
        """
        # Gerar embedding da entidade
        entity_embedding = self.model.encode(entity.label, convert_to_numpy=True)
        
        # Busca por similaridade no Neo4j (usando Vector Index)
        similar_entities = await self.kg_repository.find_similar_entities(
            embedding=entity_embedding.tolist(),
            threshold=self.similarity_threshold,
            limit=1
        )
        
        if similar_entities:
            # Usa a primeira entidade similar como can√¥nica
            canonical_entity = similar_entities[0]
            logger.info(
                f"Merging entity '{entity.label}' into existing entity '{canonical_entity.label}'",
                extra={
                    "original_label": entity.label,
                    "canonical_label": canonical_entity.label,
                    "similarity": similar_entities[0].similarity
                }
            )
            return canonical_entity
        else:
            # Cria uma nova entidade se nenhuma similar for encontrada
            new_entity = await self.kg_repository.create_entity(entity)
            # Adiciona o embedding ao n√≥ para futuras buscas
            await self.kg_repository.add_embedding_to_entity(
                entity_id=new_entity.id,
                embedding=entity_embedding.tolist()
            )
            logger.info(f"Created new entity: '{entity.label}' (ID: {new_entity.id})")
            return new_entity
```

**Benef√≠cios:**
- ‚úÖ **Qualidade do Grafo:** Garante um KG limpo, conectado e com alta integridade
- ‚úÖ **Melhora as Queries:** As buscas se tornam muito mais precisas e completas
- ‚úÖ **Reduz Ru√≠do:** Elimina duplicatas sem√¢nticas (ex: "IA", "Intelig√™ncia Artificial", "A.I.")

**Configura√ß√£o do Neo4j:**

Para usar busca por similaridade no Neo4j, √© necess√°rio:

1. Instalar plugin de vector index (ex: `neo4j-vector`)
2. Criar √≠ndice vetorial para entidades
3. Armazenar embeddings nos n√≥s

```cypher
// Criar √≠ndice vetorial (exemplo)
CREATE VECTOR INDEX entity_embeddings
FOR (e:Entity)
ON e.embedding
OPTIONS {indexConfig: {
  `vector.dimensions`: 384,  // all-MiniLM-L6-v2 tem 384 dimens√µes
  `vector.similarity_function`: 'cosine'
}}
```

---

## üåê 11. Governan√ßa Federada em Escala

> **üî¥ Cr√≠tica N√≠vel 2 Aplicada:** Evolu√ß√£o para um modelo de ontologia federada (semantic data mesh) para evitar gargalo de governan√ßa centralizada e permitir escalabilidade organizacional.

**O Problema Original:** O plano, mesmo sendo modular, ainda opera sob o paradigma de uma √∫nica "fonte da verdade" para a ontologia, gerenciada por uma equipe central. Isso cria um **gargalo de governan√ßa** em potencial quando diferentes unidades de neg√≥cio (Marketing, P&D, Jur√≠dico) precisam evoluir suas ontologias em ritmos diferentes.

**Por Que Importa em Escala:**
- √Ä medida que o sistema se torna um sucesso, diferentes unidades de neg√≥cio ter√£o suas pr√≥prias necessidades de modelagem
- For√ßar todos a passarem por um comit√™ central cria atrito pol√≠tico, lentid√£o e desincentiva a ado√ß√£o
- O processo de versionamento centralizado se torna o novo "deploy de monolito"

**A Solu√ß√£o: Modelo de Ontologia Federada (Semantic Data Mesh)**

### 11.1 Arquitetura Federada

**Princ√≠pios Fundamentais:**

1. **M√∫ltiplos Reposit√≥rios de Ontologia:** Diferentes dom√≠nios de neg√≥cio podem ter seus pr√≥prios reposit√≥rios Git para suas "ontologias de aplica√ß√£o"
2. **Heran√ßa Expl√≠cita:** Cada ontologia de aplica√ß√£o deve `importar` a ontologia base (`base_schema.yaml`), que atua como "Upper Ontology" da organiza√ß√£o
3. **Registro Centralizado:** Um servi√ßo de registro (`OntologyRegistry`) descobre, carrega e compila as diferentes ontologias federadas
4. **Contextualiza√ß√£o no Processamento:** O servi√ßo de extra√ß√£o pode ser instru√≠do a usar um "contexto ontol√≥gico" espec√≠fico (ex: `base + marketing_v1.2`)

**Diagrama de Arquitetura:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Repo Ontologia   ‚îÇ      ‚îÇ Repo Ontologia   ‚îÇ      ‚îÇ Repo Ontologia   ‚îÇ
‚îÇ      Base        ‚îÇ      ‚îÇ     Marketing    ‚îÇ      ‚îÇ      P&D         ‚îÇ
‚îÇ  (base_schema)   ‚îÇ      ‚îÇ  (marketing.yaml)‚îÇ      ‚îÇ   (rnd.yaml)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ                         ‚îÇ                         ‚îÇ
          ‚îÇ imports                 ‚îÇ imports                 ‚îÇ imports
          ‚îÇ                         ‚îÇ                         ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚Üì
                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                          ‚îÇ Ontology Registry‚îÇ
                          ‚îÇ  (Servi√ßo Central)‚îÇ
                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                                    ‚Üì
      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
      ‚îÇ KnowledgeExtractionService                                 ‚îÇ
      ‚îÇ  (carrega contexto ontol√≥gico: base + domain_schema)       ‚îÇ
      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 11.2 Estrutura de Reposit√≥rios Federados

**Ontologia Base (Upper Ontology):**

```
repo-ontologia-base/
‚îú‚îÄ‚îÄ base_schema.yaml          # Ontologia base da organiza√ß√£o
‚îú‚îÄ‚îÄ core_concepts.yaml        # Conceitos core compartilhados
‚îî‚îÄ‚îÄ common_relations.yaml     # Rela√ß√µes comuns
```

**Ontologias de Dom√≠nio:**

```
repo-ontologia-marketing/
‚îú‚îÄ‚îÄ marketing_schema.yaml     # Importa base_schema.yaml
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ DECISOES.md

repo-ontologia-rnd/
‚îú‚îÄ‚îÄ rnd_schema.yaml           # Importa base_schema.yaml
‚îú‚îÄ‚îÄ biology_imports.yaml      # Importa ontologia de terceiros (ex: biologia)
‚îî‚îÄ‚îÄ README.md
```

**Exemplo de Schema Federado:**

```yaml
# repo-ontologia-marketing/marketing_schema.yaml
id: https://example.com/ontologies/marketing/v1
name: Marketing Ontology
imports:
  - https://example.com/ontologies/base/v1/base_schema

classes:
  CustomerJourney:
    is_a: Process  # Herda de conceito base
    description: "Jornada do cliente atrav√©s dos pontos de contato"
    attributes:
      stages:
        range: JourneyStage
        multivalued: true
      touchpoints:
        range: Touchpoint
        multivalued: true

  Campaign:
    is_a: Project  # Herda de conceito base
    description: "Campanha de marketing"
    attributes:
      target_audience:
        range: AudienceSegment
      metrics:
        range: CampaignMetric
        multivalued: true
```

### 11.3 Servi√ßo de Registro de Ontologias

**`OntologyRegistry`: Descoberta e Compila√ß√£o**

```python
# backend/app/services/ontology_registry.py
from pathlib import Path
import yaml
from linkml_runtime import SchemaView
from typing import Dict, List, Optional
import logging

logger = logging.getLogger(__name__)

class OntologyRegistry:
    """Registra e gerencia ontologias federadas."""
    
    def __init__(self, base_ontology_path: Path, domain_ontologies_dir: Path):
        self.base_ontology_path = base_ontology_path
        self.domain_ontologies_dir = domain_ontologies_dir
        self._registry: Dict[str, SchemaView] = {}
        self._load_base_ontology()
        self._discover_domain_ontologies()
    
    def _load_base_ontology(self):
        """Carrega a ontologia base (Upper Ontology)."""
        try:
            base_schema = SchemaView(str(self.base_ontology_path))
            self._registry["base"] = base_schema
            logger.info(f"Base ontology loaded from {self.base_ontology_path}")
        except Exception as e:
            logger.error(f"Failed to load base ontology: {e}")
            raise
    
    def _discover_domain_ontologies(self):
        """Descobre e carrega ontologias de dom√≠nio."""
        for domain_file in self.domain_ontologies_dir.glob("**/*_schema.yaml"):
            domain_name = domain_file.stem.replace("_schema", "")
            try:
                domain_schema = SchemaView(str(domain_file))
                # Resolve imports (incluindo base)
                domain_schema.merge_schemas([self._registry["base"].schema])
                self._registry[domain_name] = domain_schema
                logger.info(f"Domain ontology '{domain_name}' loaded from {domain_file}")
            except Exception as e:
                logger.warning(f"Failed to load domain ontology {domain_file}: {e}")
    
    def get_ontology_context(
        self, 
        domains: List[str] = None
    ) -> SchemaView:
        """
        Retorna um contexto ontol√≥gico combinado.
        
        Args:
            domains: Lista de dom√≠nios a incluir (ex: ["marketing", "rnd"])
                    Se None, retorna apenas base.
        
        Returns:
            SchemaView com ontologias combinadas
        """
        if domains is None:
            return self._registry["base"]
        
        # Come√ßa com base
        combined_schema = self._registry["base"].schema
        
        # Merge cada dom√≠nio solicitado
        for domain in domains:
            if domain not in self._registry:
                logger.warning(f"Domain '{domain}' not found in registry. Skipping.")
                continue
            # Merge schema (resolver conflitos de nomes se necess√°rio)
            combined_schema = self._merge_schemas(
                combined_schema, 
                self._registry[domain].schema
            )
        
        return SchemaView(combined_schema)
    
    def list_available_domains(self) -> List[str]:
        """Retorna lista de dom√≠nios registrados."""
        return [name for name in self._registry.keys() if name != "base"]
    
    def _merge_schemas(self, base_schema, domain_schema):
        """Merge dois schemas LinkML (simplificado - na pr√°tica usar linkml-runtime)."""
        # Implementa√ß√£o simplificada - na pr√°tica, usar biblioteca LinkML
        # para resolver imports e merge corretamente
        merged_classes = {**base_schema.classes, **domain_schema.classes}
        merged_slots = {**base_schema.slots, **domain_schema.slots}
        
        # Criar novo schema merged (pseudoc√≥digo - usar SchemaDefinition do LinkML)
        merged_schema = base_schema.__class__()
        merged_schema.classes = merged_classes
        merged_schema.slots = merged_slots
        # ... copiar outros campos
        
        return merged_schema
```

### 11.4 Integra√ß√£o com KnowledgeExtractionService

**Contextualiza√ß√£o no Processamento:**

```python
# backend/app/services/knowledge_extraction_service.py (atualizado)
class KnowledgeExtractionService:
    """Service para extra√ß√£o de conhecimento usando OntoGPT com contexto ontol√≥gico."""
    
    def __init__(self, ontology_registry: OntologyRegistry):
        self.ontology_registry = ontology_registry
        self.nlp = spacy.load("en_core_web_sm")
    
    async def extract_from_document(
        self,
        document_content: str,
        ontology_context: List[str] = None,  # Ex: ["marketing", "rnd"]
        schema_path: Optional[Path] = None
    ) -> ExtractedKnowledge:
        """
        Extrai conhecimento usando contexto ontol√≥gico espec√≠fico.
        
        Args:
            document_content: Conte√∫do do documento
            ontology_context: Lista de dom√≠nios a incluir (None = apenas base)
            schema_path: Override manual (opcional)
        """
        # Se n√£o especificado, usar contexto ontol√≥gico
        if schema_path is None:
            schema_view = self.ontology_registry.get_ontology_context(ontology_context)
            # Compilar schema combinado para arquivo tempor√°rio
            temp_schema_path = self._compile_combined_schema(schema_view)
            schema_path = temp_schema_path
        
        try:
            result = extract(
                input_text=document_content,
                template="Document",
                schema=str(schema_path)
            )
            return ExtractedKnowledge(
                entities=result.extracted_object.get("entities", []),
                concepts=result.extracted_object.get("concepts", []),
                relations=result.extracted_object.get("extracted_relations", []),
                extraction_method="ontogpt",
                ontology_context=ontology_context or ["base"]
            )
        except Exception as e:
            logger.error(f"OntoGPT extraction failed: {e}. Using fallback.", exc_info=True)
            return await self._fallback_extraction(document_content)
    
    def _compile_combined_schema(self, schema_view: SchemaView) -> Path:
        """Compila schema combinado para arquivo tempor√°rio."""
        # Exportar schema para YAML
        temp_path = Path(f"/tmp/combined_schema_{uuid.uuid4()}.yaml")
        with open(temp_path, "w") as f:
            yaml.dump(schema_view.schema, f)
        return temp_path
```

### 11.5 Gest√£o de Conflitos e Resolu√ß√£o de Namespaces

**Estrat√©gia de Resolu√ß√£o de Conflitos:**

```python
# backend/app/services/ontology_registry.py (adicionar)
class OntologyRegistry:
    # ... c√≥digo anterior ...
    
    def resolve_namespace_conflicts(
        self,
        base_schema: SchemaDefinition,
        domain_schema: SchemaDefinition
    ) -> SchemaDefinition:
        """
        Resolve conflitos de nomes quando duas ontologias definem
        o mesmo conceito com significados diferentes.
        
        Estrat√©gia:
        - Se conceito existe apenas em base: usar base
        - Se conceito existe apenas em domain: adicionar com namespace
        - Se existe em ambos com mesmo significado (hash): usar base (evitar duplicata)
        - Se existe em ambos com significado diferente: prefixar domain (ex: "Marketing::Project")
        """
        merged_classes = {}
        
        # Mapear classes da base
        for class_name, class_def in base_schema.classes.items():
            merged_classes[class_name] = class_def
        
        # Adicionar classes do domain (resolver conflitos)
        for class_name, class_def in domain_schema.classes.items():
            if class_name in merged_classes:
                # Conflito detectado - verificar se √© mesmo conceito
                if self._same_concept(merged_classes[class_name], class_def):
                    # Mesmo conceito - manter base (evitar duplicata)
                    logger.info(f"Concept '{class_name}' already in base. Using base definition.")
                    continue
                else:
                    # Conceito diferente - prefixar com namespace
                    prefixed_name = f"{domain_schema.name}::{class_name}"
                    merged_classes[prefixed_name] = class_def
                    logger.warning(
                        f"Namespace conflict: '{class_name}' has different meanings. "
                        f"Domain version prefixed as '{prefixed_name}'"
                    )
            else:
                # Sem conflito - adicionar normalmente
                merged_classes[class_name] = class_def
        
        # Criar schema merged
        merged_schema = SchemaDefinition(
            name=f"{base_schema.name}_merged",
            classes=merged_classes,
            # ... outros campos
        )
        
        return merged_schema
    
    def _same_concept(self, class1, class2) -> bool:
        """Verifica se duas defini√ß√µes de classe representam o mesmo conceito."""
        # Compara√ß√£o simplificada (na pr√°tica, usar hash sem√¢ntico ou compara√ß√£o mais sofisticada)
        return (
            class1.description == class2.description and
            class1.is_a == class2.is_a
        )
```

### 11.6 Configura√ß√£o e Descoberta Autom√°tica

**Configura√ß√£o via Arquivo:**

```yaml
# backend/config/ontology_registry.yaml
ontology_registry:
  base_ontology:
    path: "ontologies/schemas/v1/base_schema.yaml"
    repository: "https://github.com/org/repo-ontologia-base"
  
  domain_ontologies:
    - name: "marketing"
      path: "ontologies/schemas/marketing/marketing_schema.yaml"
      repository: "https://github.com/org/repo-ontologia-marketing"
      auto_update: true
    
    - name: "rnd"
      path: "ontologies/schemas/rnd/rnd_schema.yaml"
      repository: "https://github.com/org/repo-ontologia-rnd"
      auto_update: true
    
    - name: "legal"
      path: "ontologies/schemas/legal/legal_schema.yaml"
      repository: "https://github.com/org/repo-ontologia-legal"
      auto_update: false  # Requer aprova√ß√£o manual
```

**Worker de Atualiza√ß√£o Autom√°tica:**

```python
# backend/app/workers/ontology_registry_worker.py
@app.task
async def update_ontology_registry():
    """
    Worker peri√≥dico para atualizar ontologias federadas dos reposit√≥rios Git.
    
    Roda diariamente e verifica se h√° novas vers√µes das ontologias de dom√≠nio.
    """
    config = load_ontology_registry_config()
    registry = OntologyRegistry(...)
    
    for domain in config.domain_ontologies:
        if not domain.auto_update:
            continue
        
        # Clonar/pull do reposit√≥rio Git
        repo_path = clone_or_pull_repository(domain.repository)
        
        # Validar schema
        schema_path = repo_path / domain.path
        if validate_schema(schema_path):
            # Atualizar registry
            registry.reload_domain(domain.name, schema_path)
            logger.info(f"Domain ontology '{domain.name}' updated successfully")
        else:
            logger.error(f"Invalid schema for '{domain.name}'. Update skipped.")
```

### 11.7 Benef√≠cios da Governan√ßa Federada

**Autonomia de Dom√≠nio:**
- Cada time pode evoluir sua ontologia no seu pr√≥prio ritmo
- Reduz depend√™ncia de releases centralizados

**Governan√ßa Descentralizada:**
- Reduz gargalo central e atrito pol√≠tico
- Permite especializa√ß√£o por dom√≠nio

**Escalabilidade Organizacional:**
- O modelo cresce com a organiza√ß√£o
- Facilita ado√ß√£o por diferentes unidades de neg√≥cio

**Flexibilidade e Reuso:**
- Ontologia base garante vocabul√°rio comum
- Dom√≠nios podem importar e estender conforme necess√°rio

**Riscos Mitigados:**
- ‚úÖ **Gargalo de Governan√ßa:** Removido atrav√©s de autonomia de dom√≠nio
- ‚úÖ **Atrito Pol√≠tico:** Reduzido atrav√©s de governan√ßa descentralizada
- ‚úÖ **Escalabilidade Limitada:** Resolvido atrav√©s de arquitetura federada

---

## üìö 12. Documenta√ß√£o e Governan√ßa

### 12.1 Estrutura de Documenta√ß√£o

```
documentacao/ontologias/
‚îú‚îÄ‚îÄ README.md              # Vis√£o geral e introdu√ß√£o
‚îú‚îÄ‚îÄ DECISOES.md            # ADRs (Architecture Decision Records)
‚îú‚îÄ‚îÄ EVOLUCAO.md            # Hist√≥rico de vers√µes e mudan√ßas
‚îú‚îÄ‚îÄ GLOSSARIO.md           # Gloss√°rio de termos
‚îú‚îÄ‚îÄ COMPETENCY_QUESTIONS.md # Perguntas de compet√™ncia
‚îî‚îÄ‚îÄ GUIA_DESENVOLVIMENTO.md # Guia para desenvolvedores
```

### 12.2 Decis√µes de Modelagem (ADRs)

**Template:**

```markdown
# ADR-001: Estrutura Modular de Ontologias

## Status
Aceito

## Contexto
Necessidade de organizar ontologias de forma modular e escal√°vel.

## Decis√£o
Usar estrutura modular com ontologia base e m√≥dulos especializados.

## Consequ√™ncias
- ‚úÖ Facilita manuten√ß√£o
- ‚úÖ Permite reuso
- ‚ö†Ô∏è Requer gerenciamento de imports
```

### 12.3 Gloss√°rio de Termos

**Manter gloss√°rio atualizado:**

```markdown
# documentacao/ontologias/GLOSSARIO.md

## Termos da Ontologia

### Concept
Conceito extra√≠do ou definido no sistema. Representa uma ideia ou no√ß√£o.

### Entity
Entidade nomeada extra√≠da de documentos (pessoas, organiza√ß√µes, locais).

### Relation
Rela√ß√£o entre entidades ou conceitos (ex: "documento A menciona entidade B").

...
```

---

## üé® 7. Experi√™ncia do Usu√°rio e Ciclo de Feedback

> **üî¥ Cr√≠tica Cr√≠tica Aplicada:** Conecta a arquitetura t√©cnica ao valor tang√≠vel para o usu√°rio final, garantindo que a complexidade se traduza em benef√≠cios claros.

### 7.1 Paradoxo da Complexidade vs. Valor

**O Problema:** Uma arquitetura tecnicamente impressionante (LinkML ‚Üí OWL ‚Üí Neo4j ‚Üí PostgreSQL) s√≥ ter√° sucesso se traduzir complexidade t√©cnica em valor claro e tang√≠vel para o usu√°rio final.

**A Solu√ß√£o:** Definir explicitamente como a interface do usu√°rio exp√µe o poder do Knowledge Graph e como os usu√°rios interagem com o sistema enriquecido.

### 7.2 Interface de Usu√°rio e Funcionalidades

**Mockup Conceitual da Busca Melhorada:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Busca Sem√¢ntica                                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  [Buscar documentos sobre "ontologias em IA"...]  [üîç] ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Resultados (3 documentos encontrados)                  ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ üìÑ Artigo: "Ontologias em Agentes de IA"        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    ‚úÖ 15 entidades identificadas                 ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    üîó 8 documentos relacionados                  ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    üìä 5 conceitos principais                     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    [Ver relacionamentos ‚Üí]  [Validar entidades] ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ üìÑ Paper: "Knowledge Graphs e LLMs"             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    ‚úÖ 12 entidades identificadas                 ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    üîó 6 documentos relacionados                  ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    üìä 4 conceitos principais                     ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Funcionalidades Chave da UI:**

1. **Visualiza√ß√£o de Relacionamentos (Graph View):**
   - Bot√£o "Ver relacionamentos" abre visualiza√ß√£o de grafo
   - Usu√°rio v√™ documentos, conceitos e entidades conectados
   - Navega√ß√£o interativa pelo Knowledge Graph

2. **Links para Entidades Relacionadas:**
   - Cada entidade extra√≠da √© clic√°vel
   - Mostra todos os documentos que mencionam a mesma entidade
   - Facilita descoberta de conhecimento relacionado

3. **Filtros Facetados Baseados em Ontologia:**
   - Filtrar por conceitos
   - Filtrar por tipos de entidades (pessoas, organiza√ß√µes, etc)
   - Filtrar por rela√ß√µes (ex: "documentos que referenciam X")

4. **Busca Multi-hop (Killer Feature):**
   - Query exemplo: "Documentos sobre IA que tamb√©m mencionam ontologias e foram publicados ap√≥s 2020"
   - Combina busca vetorial (RAG) com racioc√≠nio de grafo

### 7.3 Fluxo de Feedback do Usu√°rio

**Ciclo de Feedback Completo:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  1. Usu√°rio Encontra Problema                           ‚îÇ
‚îÇ     Ex: Entidade "IA" foi extra√≠da incorretamente      ‚îÇ
‚îÇ         como "Intelig√™ncia Artificial Corp"            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
                        ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  2. Reporte na UI                                       ‚îÇ
‚îÇ     - Bot√£o "Reportar erro" na entidade                ‚îÇ
‚îÇ     - Formul√°rio: Tipo de erro, descri√ß√£o              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
                        ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  3. Cria√ß√£o de Ticket de Valida√ß√£o                      ‚îÇ
‚îÇ     - Salvo em PostgreSQL (extraction_validations)     ‚îÇ
‚îÇ     - Status: "pending_review"                         ‚îÇ
‚îÇ     - Atribu√≠do a especialista de dom√≠nio              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
                        ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  4. Valida√ß√£o no Dashboard                              ‚îÇ
‚îÇ     - Especialista revisa no dashboard                 ‚îÇ
‚îÇ     - Corrige entidade/conceito/rela√ß√£o                ‚îÇ
‚îÇ     - Aprova ou rejeita                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
                        ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  5. Atualiza√ß√£o do Knowledge Graph                      ‚îÇ
‚îÇ     - Corre√ß√£o aplicada no Neo4j                       ‚îÇ
‚îÇ     - Feedback salvo para fine-tuning                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
                        ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  6. Feedback para Schema (Opcional, Peri√≥dico)         ‚îÇ
‚îÇ     - M√∫ltiplos feedbacks similares                    ‚îÇ
‚îÇ     - Gera PR para atualizar schema LinkML             ‚îÇ
‚îÇ     - Vers√£o nova da ontologia                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Diagrama de Sequ√™ncia - Reporte de Erro:**

```
Usu√°rio    Frontend    Backend API    PostgreSQL    Neo4j    Dashboard
  ‚îÇ            ‚îÇ            ‚îÇ              ‚îÇ          ‚îÇ          ‚îÇ
  ‚îÇ‚îÄ‚îÄReport‚îÄ‚îÄ>‚îÇ            ‚îÇ              ‚îÇ          ‚îÇ          ‚îÇ
  ‚îÇ            ‚îÇ‚îÄ‚îÄPOST‚îÄ‚îÄ>  ‚îÇ              ‚îÇ          ‚îÇ          ‚îÇ
  ‚îÇ            ‚îÇ  /validations           ‚îÇ          ‚îÇ          ‚îÇ
  ‚îÇ            ‚îÇ            ‚îÇ‚îÄ‚îÄINSERT‚îÄ‚îÄ>  ‚îÇ          ‚îÇ          ‚îÇ
  ‚îÇ            ‚îÇ            ‚îÇ  (validation)          ‚îÇ          ‚îÇ
  ‚îÇ            ‚îÇ<‚îÄ‚îÄ201‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ              ‚îÇ          ‚îÇ          ‚îÇ
  ‚îÇ<‚îÄ‚îÄSuccess‚îÄ‚îÄ‚îÇ            ‚îÇ              ‚îÇ          ‚îÇ          ‚îÇ
  ‚îÇ            ‚îÇ            ‚îÇ              ‚îÇ          ‚îÇ          ‚îÇ
  ‚îÇ            ‚îÇ            ‚îÇ              ‚îÇ          ‚îÇ          ‚îÇ
  ‚îÇ            ‚îÇ            ‚îÇ              ‚îÇ          ‚îÇ‚îÄ‚îÄNotify‚îÄ‚îÄ>‚îÇ
  ‚îÇ            ‚îÇ            ‚îÇ              ‚îÇ          ‚îÇ          ‚îÇ
  ‚îÇ            ‚îÇ            ‚îÇ              ‚îÇ          ‚îÇ<‚îÄ‚îÄReview‚îÄ‚îÄ‚îÇ
  ‚îÇ            ‚îÇ            ‚îÇ              ‚îÇ          ‚îÇ          ‚îÇ
  ‚îÇ            ‚îÇ            ‚îÇ<‚îÄ‚îÄUpdate‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ          ‚îÇ          ‚îÇ
  ‚îÇ            ‚îÇ            ‚îÇ  (approved)  ‚îÇ          ‚îÇ          ‚îÇ
  ‚îÇ            ‚îÇ            ‚îÇ‚îÄ‚îÄApply‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ          ‚îÇ          ‚îÇ
  ‚îÇ            ‚îÇ            ‚îÇ  (to Neo4j)  ‚îÇ          ‚îÇ          ‚îÇ
```

### 7.4 M√©tricas de Valor de Neg√≥cio

**Al√©m das m√©tricas t√©cnicas, definir m√©tricas de valor de neg√≥cio:**

```python
# M√©tricas de Valor de Neg√≥cio
class BusinessMetrics:
    """M√©tricas que medem o valor entregue aos usu√°rios."""
    
    # M√©tricas de Efici√™ncia
    time_to_find_related_documents: float  # Redu√ß√£o de 30% no tempo
    documents_discovered_via_relations: int  # Aumento de 25% em descoberta
    
    # M√©tricas de Qualidade
    search_result_relevance_score: float  # NPS de relev√¢ncia
    user_satisfaction_with_relations: float  # Feedback direto dos usu√°rios
    
    # M√©tricas de Uso
    graph_navigation_usage_rate: float  # % de usu√°rios que usam visualiza√ß√£o de grafo
    entity_click_through_rate: float  # % de entidades clicadas
    
    # M√©tricas de Impacto
    cross_reference_usage_in_projects: int  # Refer√™ncias cruzadas em novos projetos
    knowledge_reuse_rate: float  # Reuso de conceitos entre projetos
```

**Exemplos de Objetivos:**

- ‚úÖ **Redu√ß√£o de 30%** no tempo gasto para encontrar documentos relacionados
- ‚úÖ **Aumento de 25%** no uso de refer√™ncias cruzadas em novos projetos
- ‚úÖ **Melhoria de 40%** na relev√¢ncia dos resultados de busca (m√©trica NPS)
- ‚úÖ **Taxa de ado√ß√£o de 60%** para visualiza√ß√£o de relacionamentos

### 7.5 Killer Features Habilitadas pela Arquitetura

**O que esta arquitetura habilita que RAG puro n√£o conseguiria:**

1. **Busca Multi-hop:**
   - Query: "Documentos que mencionam 'ontologias' E tamb√©m citam 'Stanford' E foram criados por projetos relacionados a 'IA'"
   - **Por qu√™ importa:** Permite descobrir conex√µes n√£o √≥bvias entre documentos

2. **Navega√ß√£o Expl√≠cita:**
   - Clicar em uma entidade mostra todos os documentos relacionados
   - N√£o precisa fazer nova busca, a rela√ß√£o j√° est√° no grafo
   - **Por qu√™ importa:** Facilita explora√ß√£o e descoberta de conhecimento

3. **Agrega√ß√£o Sem√¢ntica:**
   - "Quais s√£o os conceitos mais comuns nos documentos deste projeto?"
   - "Qual √© a rede de relacionamentos entre as refer√™ncias?"
   - **Por qu√™ importa:** Insights agregados que n√£o s√£o poss√≠veis apenas com busca vetorial

---

## üîó 8. Integra√ß√£o com Sistema Existente

### 8.1 Fluxo de Integra√ß√£o Completo

```
Upload de Documento
    ‚Üì
1. Google File Search (RAG) - MANT√âM
    ‚Üì
2. OntoGPT Extraction (NOVO)
   - Usa schema LinkML
   - Extrai entidades, conceitos, rela√ß√µes
    ‚Üì
3. Valida√ß√£o (NOVO)
   - Valida contra schema
   - Remove duplicatas
    ‚Üì
4. Knowledge Graph (NOVO)
   - Cria n√≥s no Neo4j
   - Cria rela√ß√µes
    ‚Üì
5. PostgreSQL (ATUALIZA)
   - Salva metadata
   - Salva entidades/conceitos em JSONB
   - Atualiza campos de ontologia
    ‚Üì
6. Busca H√≠brida (NOVO)
   - Busca vetorial (Google File Search)
   - Busca simb√≥lica (Knowledge Graph)
   - Fus√£o de resultados
```

### 8.2 Service de Ontologia

```python
# backend/app/services/ontology_service.py
class OntologyService:
    """Service para gest√£o de ontologias."""
    
    def __init__(self, db: AsyncSession):
        self.db = db
        self.extraction_service = KnowledgeExtractionService()
        self.kg_repository = KnowledgeGraphRepository()
        self.document_repository = DocumentRepository(db)
    
    async def process_document_ontology(
        self, 
        document_id: UUID,
        document_content: str
    ) -> ProcessedOntology:
        """
        Processa ontologia de um documento.
        
        Args:
            document_id: ID do documento
            document_content: Conte√∫do do documento
            
        Returns:
            ProcessedOntology com entidades, conceitos e rela√ß√µes
        """
        # 1. Extrair conhecimento
        extracted = await self.extraction_service.extract_from_document(
            document_content
        )
        
        # 2. Validar
        validated = await self._validate_knowledge(extracted)
        
        # 3. Popular Knowledge Graph
        kg_result = await self.kg_repository.create_from_extraction(
            document_id=document_id,
            knowledge=validated
        )
        
        # 4. Atualizar documento no PostgreSQL
        await self.document_repository.update_ontology_fields(
            document_id=document_id,
            concepts=validated.concepts,
            entities=validated.entities,
            relations=validated.relations,
            ontology_version="1.0.0"
        )
        
        return ProcessedOntology(
            document_id=document_id,
            entities=validated.entities,
            concepts=validated.concepts,
            relations=validated.relations,
            kg_nodes=kg_result.nodes_created,
            kg_relations=kg_result.relations_created
        )
```

---

## ‚úÖ 9. Checklist de Implementa√ß√£o

### Fase 1: Estrutura Base (Semana 1)

- [ ] Criar estrutura de diret√≥rios
- [ ] Criar schema LinkML base (`base_schema.yaml`)
- [ ] Criar schema de documentos (`document_schema.yaml`)
- [ ] Configurar OntoGPT
- [ ] **Criar `KnowledgeExtractionService` com estrat√©gia de fallback (spaCy)** ‚≠ê
- [ ] **Instalar e configurar spaCy** (`python -m spacy download en_core_web_sm`)
- [ ] **Criar `EntityResolutionService` com deduplica√ß√£o b√°sica** ‚≠ê
- [ ] **Instalar SentenceTransformers** (`pip install sentence-transformers`)
- [ ] Testes b√°sicos de extra√ß√£o
- [ ] Testes unit√°rios para os novos services

### Fase 2: Integra√ß√£o (Semana 2)

- [ ] Integrar extra√ß√£o no `DocumentService`
- [ ] Popular Knowledge Graph (Neo4j)
- [ ] **Configurar Vector Index no Neo4j para busca de similaridade** ‚≠ê
- [ ] Integrar `EntityResolutionService` no fluxo de processamento
- [ ] Atualizar models SQLAlchemy
- [ ] Atualizar `DocumentRepository`
- [ ] **Criar testes de integra√ß√£o baseados nas Perguntas de Compet√™ncia** ‚≠ê
- [ ] Testes de integra√ß√£o gerais

### Fase 3: Versionamento e Governan√ßa (Semana 3)

- [ ] Setup de versionamento (Git tags)
- [ ] Scripts de build (LinkML ‚Üí OWL)
- [ ] Processo de valida√ß√£o
- [ ] **Implementar padr√£o Outbox para sincroniza√ß√£o** ‚≠ê‚≠ê
- [ ] **Criar tabela ontology_outbox** ‚≠ê‚≠ê
- [ ] **Criar worker de sincroniza√ß√£o Neo4j (Celery/RQ)** ‚≠ê‚≠ê
- [ ] **Iniciar desenvolvimento do Framework de Curadoria Ativa** ‚≠ê
- [ ] **Implementar Active Learning Service** ‚≠ê
- [ ] **Adicionar logging de custo de API (OpenAI)** ‚≠ê
- [ ] Documenta√ß√£o inicial

### Fase 4: Evolu√ß√£o e Otimiza√ß√£o (Cont√≠nuo)

- [ ] Processo de refinamento
- [ ] Perguntas de compet√™ncia
- [ ] ADRs (Decis√µes)
- [ ] Gloss√°rio
- [ ] **Configurar pipeline de testes de performance (CI/CD)** ‚≠ê
- [ ] **Dashboard de monitoramento de custos** ‚≠ê
- [ ] **Implementar gamifica√ß√£o e leaderboard** ‚≠ê
- [ ] **Criar service de fine-tuning peri√≥dico** ‚≠ê
- [ ] **Implementar m√©tricas de valor de neg√≥cio** ‚≠ê‚≠ê
- [ ] **Criar UI para visualiza√ß√£o de relacionamentos** ‚≠ê‚≠ê
- [ ] **Implementar busca multi-hop na interface** ‚≠ê‚≠ê
- [ ] Monitoramento e feedback

---

## üìä 10. M√©tricas e Monitoramento

### 10.1 M√©tricas de Qualidade (T√©cnicas)

- **Cobertura:** % de documentos com ontologia processada
- **Precis√£o:** Valida√ß√£o manual de extra√ß√µes
- **Completude:** % de campos preenchidos
- **Consist√™ncia:** Conflitos entre vers√µes
- **Taxa de Deduplica√ß√£o:** % de entidades que foram mescladas (resolu√ß√£o)
- **Taxa de Sincroniza√ß√£o:** % de eventos outbox processados com sucesso
- **Lat√™ncia de Sincroniza√ß√£o:** Tempo m√©dio entre cria√ß√£o de evento e sincroniza√ß√£o no Neo4j

### 10.1.1 M√©tricas de Valor de Neg√≥cio

> **üî¥ Cr√≠tica Cr√≠tica Aplicada:** M√©tricas que medem valor real para usu√°rios, n√£o apenas m√©tricas t√©cnicas.

**M√©tricas de Efici√™ncia:**
- **Tempo m√©dio para encontrar documentos relacionados:** Objetivo: Redu√ß√£o de 30%
- **Taxa de descoberta via rela√ß√µes:** % de documentos descobertos atrav√©s de navega√ß√£o de grafo
- **Uso de busca multi-hop:** % de queries que utilizam racioc√≠nio de grafo

**M√©tricas de Qualidade Percebida:**
- **NPS de relev√¢ncia de busca:** Net Promoter Score dos resultados
- **Taxa de cliques em entidades relacionadas:** Engajamento com funcionalidades de grafo
- **Taxa de uso de visualiza√ß√£o de relacionamentos:** Ado√ß√£o da feature de grafo

**M√©tricas de Impacto:**
- **Taxa de reuso de conhecimento:** Conceitos reutilizados entre projetos
- **Refer√™ncias cruzadas em novos projetos:** Aumento de 25% no uso de refer√™ncias relacionadas
- **Taxa de valida√ß√£o humana:** % de extra√ß√µes validadas (meta: 60%+)
- **Pontua√ß√£o m√©dia de curadores:** Engajamento no framework de curadoria

**Dashboard de M√©tricas de Neg√≥cio:**

```python
# backend/app/api/v1/endpoints/metrics.py
@router.get("/metrics/business")
async def get_business_metrics(
    period: str = "month"
) -> BusinessMetricsResponse:
    """
    Retorna m√©tricas de valor de neg√≥cio.
    """
    metrics_service = BusinessMetricsService()
    
    return BusinessMetricsResponse(
        period=period,
        efficiency=await metrics_service.get_efficiency_metrics(period),
        quality=await metrics_service.get_quality_metrics(period),
        impact=await metrics_service.get_impact_metrics(period),
        trends=await metrics_service.get_trends(period)
    )
```

### 10.2 Logging Estruturado

```python
# Log de opera√ß√µes de ontologia
logger.info(
    "Ontology extraction completed",
    extra={
        "document_id": document_id,
        "entities_count": len(entities),
        "concepts_count": len(concepts),
        "relations_count": len(relations),
        "ontology_version": "1.0.0",
        "processing_time_ms": processing_time,
        "extraction_method": extraction_method,  # "ontogpt" ou "spacy_fallback"
        "fallback_used": extraction_method == "spacy_fallback"
    }
)
```

### 10.3 An√°lise de Custo e Monitoramento de API

> **Melhoria de Governan√ßa:** Monitoramento de custos de APIs externas (OpenAI) para controle financeiro e visibilidade operacional.

**Logging de Custo:**

```python
# backend/app/services/knowledge_extraction_service.py
def _calculate_openai_cost(self, tokens: int, model: str = "gpt-4-turbo") -> float:
    """
    Calcula o custo de uma chamada √† API OpenAI.
    
    Args:
        tokens: N√∫mero total de tokens (input + output)
        model: Modelo usado (gpt-4-turbo, gpt-3.5-turbo, etc)
        
    Returns:
        Custo em USD
    """
    # Pre√ßos por 1K tokens (exemplo para GPT-4 Turbo)
    prices = {
        "gpt-4-turbo": {"input": 0.01, "output": 0.03},
        "gpt-3.5-turbo": {"input": 0.001, "output": 0.002},
    }
    
    model_prices = prices.get(model, prices["gpt-4-turbo"])
    # Estimativa: 70% input, 30% output (ajustar conforme necess√°rio)
    input_tokens = int(tokens * 0.7)
    output_tokens = int(tokens * 0.3)
    
    cost = (input_tokens / 1000 * model_prices["input"]) + \
           (output_tokens / 1000 * model_prices["output"])
    
    return cost

async def extract_from_document(self, document_content: str) -> ExtractedKnowledge:
    try:
        result = extract(...)
        
        # Logging de custo (se dispon√≠vel na resposta)
        if hasattr(result, 'response_metadata'):
            total_tokens = result.response_metadata.get('total_tokens', 0)
            cost = self._calculate_openai_cost(total_tokens)
            
            logger.info(
                "OntoGPT API call completed",
                extra={
                    "tokens": total_tokens,
                    "cost_usd": cost,
                    "model": "gpt-4-turbo"
                }
            )
        
        return ExtractedKnowledge(...)
    except Exception as e:
        # ... fallback ...
```

**Dashboard de Monitoramento:**

M√©tricas a serem monitoradas (usando Grafana, Datadog ou similar):

1. **Custo Total:**
   - Custo di√°rio/mensal de APIs
   - Custo m√©dio por documento
   - Documentos mais caros para processar

2. **Performance:**
   - Lat√™ncia de extra√ß√£o (p50, p95, p99)
   - Taxa de fallback (spaCy usado)
   - Throughput (documentos/minuto)

3. **Qualidade:**
   - Taxa de deduplica√ß√£o
   - N√∫mero de entidades/conceitos extra√≠dos
   - Taxa de valida√ß√£o humana (aprovado/rejeitado)

**Alertas Configurados:**

```python
# Exemplo de alerta de custo
if daily_cost > BUDGET_LIMIT:
    send_alert(
        level="warning",
        message=f"Daily API cost ({daily_cost:.2f} USD) exceeded budget ({BUDGET_LIMIT} USD)"
    )
```

### 10.4 Testes de Performance

> **Melhoria de Otimiza√ß√£o:** Pipeline de testes de performance para detectar regress√µes antes da produ√ß√£o.

**Testes de Performance:**

```python
# backend/tests/ontologies/test_performance.py
import pytest
from time import time
import asyncio

@pytest.mark.performance
@pytest.mark.asyncio
async def test_extraction_latency_for_standard_document(ontology_service):
    """Verifica se a extra√ß√£o de um documento padr√£o leva menos de 10s."""
    standard_content = "A" * 50000  # ~50KB de texto
    
    start_time = time()
    result = await ontology_service.extract_from_document(standard_content)
    duration = time() - start_time
    
    assert duration < 10.0, f"Extra√ß√£o muito lenta: {duration:.2f}s (limite: 10s)"
    assert result.entities_count > 0, "Nenhuma entidade extra√≠da"

@pytest.mark.performance
@pytest.mark.asyncio
async def test_extraction_latency_for_large_document(ontology_service):
    """Verifica se a extra√ß√£o de um documento grande (10MB) leva menos de 30s."""
    large_content = "A" * 10_000_000  # ~10MB
    
    start_time = time()
    result = await ontology_service.extract_from_document(large_content)
    duration = time() - start_time
    
    assert duration < 30.0, f"Extra√ß√£o muito lenta para documento grande: {duration:.2f}s (limite: 30s)"

@pytest.mark.performance
@pytest.mark.asyncio
async def test_query_latency_competency_questions(ontology_service, test_kg):
    """Verifica lat√™ncia das principais queries de compet√™ncia."""
    queries = [
        ("find_documents_by_concept", "Intelig√™ncia Artificial"),
        ("find_related_documents", "doc-123"),
        ("find_concepts_in_document", "doc-456"),
    ]
    
    for query_name, param in queries:
        start_time = time()
        result = await ontology_service.execute_competency_query(query_name, param)
        duration = time() - start_time
        
        assert duration < 2.0, \
            f"Query '{query_name}' muito lenta: {duration:.2f}s (limite: 2s)"
```

**Integra√ß√£o com CI/CD:**

```yaml
# .github/workflows/performance-tests.yml
name: Performance Tests

on:
  pull_request:
    paths:
      - 'backend/app/services/ontology_service.py'
      - 'backend/app/services/knowledge_extraction_service.py'

jobs:
  performance-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Run performance tests
        run: |
          pytest backend/tests/ontologies/test_performance.py \
            -m performance \
            --durations=10
```

### 10.5 Framework de Curadoria Ativa

> **üü† Cr√≠tica Cr√≠tica Aplicada:** Transforma o "Dashboard de Valida√ß√£o" em um framework operacional que resolve o problema do "humano no loop" atrav√©s de gamifica√ß√£o, aprendizado ativo e integra√ß√£o ao fluxo de trabalho.

**O Problema Original:** O dashboard se tornaria um "cemit√©rio de valida√ß√µes pendentes" sem fluxo de trabalho bem definido e incentivos claros.

**A Solu√ß√£o:** Framework de Curadoria Ativa com 3 pilares:

#### 10.5.1 Dashboard de Valida√ß√£o (Base)

**Requisitos da Interface:**

1. **Visualiza√ß√£o:**
   - Texto original com entidades/conceitos destacados
   - Rela√ß√µes visualizadas graficamente
   - Confian√ßa de extra√ß√£o exibida
   - **Prioriza√ß√£o autom√°tica** (Active Learning)

2. **A√ß√µes:**
   - Aprovar/Rejeitar extra√ß√£o completa
   - Editar entidades (adicionar/remover/modificar)
   - Editar rela√ß√µes
   - Adicionar conceitos manualmente

3. **Feedback Loop:**
   - Corre√ß√µes salvas como dataset de treino
   - M√©tricas de taxa de aprova√ß√£o
   - Hist√≥rico de corre√ß√µes

**Estrutura de Dados para Feedback:**

```python
# Model para armazenar valida√ß√µes
class ExtractionValidation(Base):
    """Valida√ß√£o humana de extra√ß√£o."""
    __tablename__ = "extraction_validations"
    
    id = Column(UUID, primary_key=True)
    document_id = Column(UUID, ForeignKey("documents.id"))
    extraction_id = Column(UUID)  # ID da extra√ß√£o original
    validator_id = Column(String)  # ID do usu√°rio (Clerk)
    status = Column(String)  # "approved", "rejected", "modified"
    corrections = Column(JSON)  # Entidades/conceitos corrigidos
    feedback = Column(Text)  # Coment√°rios do validador
    priority_score = Column(Float)  # Score de prioridade (Active Learning)
    validated_at = Column(DateTime, server_default=func.now())
    
    # Campos para gamifica√ß√£o
    validator_contribution_score = Column(Integer, default=0)
```

#### 10.5.2 Aprendizado Ativo (Active Learning)

**Prioriza√ß√£o Inteligente de Valida√ß√µes:**

O sistema n√£o mostra todas as extra√ß√µes para valida√ß√£o. Em vez disso, usa **Aprendizado Ativo** para priorizar o que trar√° maior ganho de informa√ß√£o.

```python
# backend/app/services/active_learning_service.py
class ActiveLearningService:
    """Service para priorizar valida√ß√µes usando Active Learning."""
    
    def calculate_priority_score(
        self, 
        extraction: ExtractedKnowledge,
        document_importance: float = 1.0
    ) -> float:
        """
        Calcula score de prioridade para valida√ß√£o.
        
        Prioriza extra√ß√µes onde o modelo est√° mais "incerto"
        e que trar√£o maior ganho de informa√ß√£o.
        """
        # Fator 1: Incerteza do modelo (baixa confian√ßa = alta prioridade)
        uncertainty_score = 1.0 - extraction.average_confidence
        
        # Fator 2: Raridade de entidades (entidades novas = alta prioridade)
        entity_rarity = self._calculate_entity_rarity(extraction.entities)
        
        # Fator 3: Import√¢ncia do documento (documentos importantes = alta prioridade)
        importance_factor = document_importance
        
        # Fator 4: Diversidade (extra√ß√µes com tipos diferentes de entidades)
        diversity_score = self._calculate_diversity(extraction)
        
        # Score combinado
        priority_score = (
            uncertainty_score * 0.4 +
            entity_rarity * 0.3 +
            importance_factor * 0.2 +
            diversity_score * 0.1
        )
        
        return priority_score
    
    async def get_next_validation_batch(
        self, 
        limit: int = 10
    ) -> list[ExtractionValidation]:
        """
        Retorna pr√≥ximas extra√ß√µes a serem validadas, priorizadas.
        """
        # Buscar extra√ß√µes n√£o validadas
        unvalidated = await validation_repository.get_unvalidated_extractions()
        
        # Calcular scores de prioridade
        scored = [
            (extraction, self.calculate_priority_score(extraction))
            for extraction in unvalidated
        ]
        
        # Ordenar por prioridade (maior primeiro)
        scored.sort(key=lambda x: x[1], reverse=True)
        
        # Retornar top N
        return [extraction for extraction, score in scored[:limit]]
```

**Interface do Dashboard com Prioriza√ß√£o:**

```python
# Exemplo de endpoint da API
@router.get("/validation/queue")
async def get_validation_queue(
    user_id: str = Depends(get_current_user),
    limit: int = 10
) -> ValidationQueueResponse:
    """
    Retorna fila de valida√ß√µes priorizadas para o usu√°rio.
    
    Usa Active Learning para mostrar apenas as mais importantes.
    """
    active_learning_service = ActiveLearningService()
    queue = await active_learning_service.get_next_validation_batch(limit)
    
    return ValidationQueueResponse(
        items=queue,
        total_pending=await validation_repository.count_unvalidated(),
        estimated_time_minutes=len(queue) * 2  # Estimativa: 2min por valida√ß√£o
    )
```

#### 10.5.3 Gamifica√ß√£o e Incentivos

**Sistema de Pontua√ß√£o e Reconhecimento:**

```python
# backend/app/services/curation_gamification_service.py
class CurationGamificationService:
    """Service para gamifica√ß√£o da curadoria."""
    
    async def record_validation(
        self, 
        validator_id: str,
        validation: ExtractionValidation
    ) -> CurationScore:
        """
        Registra valida√ß√£o e atualiza pontua√ß√£o do curador.
        """
        # Calcular pontos baseados na qualidade da valida√ß√£o
        base_points = 10
        
        # Bonus por corre√ß√µes (quanto mais corre√ß√µes √∫teis, mais pontos)
        correction_bonus = len(validation.corrections) * 5
        
        # Bonus por valida√ß√µes de alta prioridade (mais impacto)
        priority_bonus = validation.priority_score * 20
        
        total_points = base_points + correction_bonus + priority_bonus
        
        # Atualizar pontua√ß√£o do usu√°rio
        await user_repository.add_curation_points(validator_id, total_points)
        
        # Verificar badges/conquistas
        badges = await self._check_badges(validator_id)
        
        return CurationScore(
            user_id=validator_id,
            points_earned=total_points,
            total_points=await user_repository.get_total_points(validator_id),
            badges_earned=badges,
            rank=await self._get_rank(validator_id)
        )
```

**Badges e Conquistas:**

- üèÜ **Curador Iniciante:** Validou 10 extra√ß√µes
- ü•á **Curador Experiente:** Validou 100 extra√ß√µes
- üéØ **Precis√£o Perfeita:** 95%+ de valida√ß√µes aprovadas
- üîç **Ca√ßador de Erros:** Encontrou e corrigiu 50 entidades incorretas
- ‚ö° **Validador R√°pido:** Validou 20 extra√ß√µes em um dia

**Leaderboard:**

```python
@router.get("/curation/leaderboard")
async def get_curation_leaderboard(
    period: str = "month"  # "week", "month", "all_time"
) -> LeaderboardResponse:
    """
    Retorna leaderboard de curadores.
    """
    leaders = await user_repository.get_top_curators(period, limit=10)
    
    return LeaderboardResponse(
        period=period,
        leaders=[
            LeaderEntry(
                user_id=user.id,
                username=user.username,
                points=user.curation_points,
                validations_count=user.validations_count,
                rank=rank + 1
            )
            for rank, user in enumerate(leaders)
        ]
    )
```

#### 10.5.4 Integra√ß√£o ao Fluxo de Trabalho

**Valida√ß√£o Contextual (N√£o Isolada):**

Em vez de pedir ao usu√°rio para ir a um dashboard separado, integrar valida√ß√£o no fluxo de trabalho existente:

1. **Antes de Usar um Documento:**
   - Ao abrir um documento na UI, mostrar banner: "Este documento tem 3 entidades n√£o validadas. Deseja validar agora? (2 min)"
   - Se o usu√°rio validar, ganha pontos e o documento fica marcado como "validado por voc√™"

2. **Durante Cria√ß√£o de Projeto:**
   - Ao criar projeto, sugerir validar entidades dos documentos relacionados
   - "Voc√™ est√° adicionando 5 documentos. Deseja validar as entidades principais agora?"

3. **Notifica√ß√µes Contextuais:**
   - "Voc√™ √© especialista em 'IA'. H√° 3 extra√ß√µes sobre este tema aguardando valida√ß√£o."

#### 10.5.5 Fine-Tuning Baseado em Feedback

**Dataset de Treino para Fine-Tuning:**

```python
# backend/app/services/fine_tuning_service.py
class FineTuningService:
    """Service para preparar dados de fine-tuning baseado em valida√ß√µes."""
    
    async def export_training_dataset(
        self,
        min_validations: int = 100
    ) -> TrainingDataset:
        """
        Exporta dataset de treino baseado em valida√ß√µes humanas.
        
        O dataset ser√° usado para fine-tune de um modelo menor (ex: Llama 3)
        que pode substituir ou complementar o GPT-4.
        """
        # Buscar valida√ß√µes aprovadas com corre√ß√µes
        validations = await validation_repository.get_approved_with_corrections(
            min_count=min_validations
        )
        
        training_examples = []
        
        for validation in validations:
            # Buscar extra√ß√£o original
            original_extraction = await extraction_repository.get_by_id(
                validation.extraction_id
            )
            
            # Criar exemplo de treino (entrada: texto, sa√≠da: extra√ß√£o corrigida)
            example = TrainingExample(
                input_text=original_extraction.document_content,
                expected_output={
                    "entities": validation.corrections.get("entities", []),
                    "concepts": validation.corrections.get("concepts", []),
                    "relations": validation.corrections.get("relations", [])
                },
                metadata={
                    "validator_id": validation.validator_id,
                    "document_id": str(validation.document_id),
                    "confidence_improvement": validation.confidence_delta
                }
            )
            training_examples.append(example)
        
        # Salvar em formato JSONL (um exemplo por linha)
        dataset_path = f"training_datasets/fine_tuning_{datetime.now().isoformat()}.jsonl"
        await self._save_jsonl(training_examples, dataset_path)
        
        # Upload para S3 (para processamento futuro)
        await s3_client.upload_file(dataset_path, "training-datasets/")
        
        return TrainingDataset(
            path=dataset_path,
            examples_count=len(training_examples),
            total_validations=len(validations)
        )
```

**Processo de Fine-Tuning Peri√≥dico:**

```python
# backend/app/workers/fine_tuning_worker.py
@app.task
def periodic_fine_tuning():
    """
    Tarefa peri√≥dica (mensal) para fine-tuning do modelo de extra√ß√£o.
    
    Usa valida√ß√µes humanas acumuladas para melhorar o modelo.
    """
    fine_tuning_service = FineTuningService()
    
    # 1. Exportar dataset
    dataset = await fine_tuning_service.export_training_dataset(min_validations=500)
    
    # 2. Treinar modelo (Llama 3 fine-tuned)
    model_path = await train_model(dataset)
    
    # 3. Validar modelo (teste em conjunto de valida√ß√£o)
    evaluation_metrics = await evaluate_model(model_path)
    
    # 4. Se m√©tricas melhorarem, fazer deploy do novo modelo
    if evaluation_metrics.f1_score > current_model_f1_score * 1.05:  # 5% de melhoria
        await deploy_model(model_path, version="v2")
        logger.info(f"Deployed improved extraction model: {evaluation_metrics}")
    
    return {
        "dataset_size": dataset.examples_count,
        "model_metrics": evaluation_metrics,
        "deployed": evaluation_metrics.f1_score > current_model_f1_score * 1.05
    }
```

### 10.5.6 MLOps e Governan√ßa de Modelos

> **üü† Cr√≠tica N√≠vel 2 Aplicada:** Framework de MLOps para governan√ßa, auditabilidade e explicabilidade de modelos fine-tuned, transformando o pipeline de fine-tuning de uma "caixa-preta" para um sistema audit√°vel e explic√°vel.

**O Problema Original:** O pipeline de fine-tuning peri√≥dico cria uma nova caixa-preta. Se o modelo fine-tuned come√ßar a fazer extra√ß√µes estranhas ou enviesadas, como depurar o problema? O processo de deploy √© baseado em m√©tricas de F1-score, mas isso n√£o captura nuances de qualidade ou vi√©s.

**Por Que Importa:**
- Em produ√ß√£o, a incapacidade de explicar ou auditar o comportamento de um modelo √© um risco significativo
- Vieses sutis podem ser introduzidos silenciosamente
- Rastreabilidade √© essencial para conformidade e confian√ßa

**A Solu√ß√£o: Framework de MLOps para Governan√ßa de Modelos**

#### 10.5.6.1 Cart√µes de Modelo (Model Cards)

**Estrutura de Model Card:**

```python
# backend/app/services/model_card_service.py
from dataclasses import dataclass
from datetime import datetime
from typing import Dict, List, Optional
import json

@dataclass
class ModelCard:
    """Cart√£o de modelo para documenta√ß√£o e governan√ßa."""
    
    model_id: str
    model_name: str
    version: str
    base_model: str  # Ex: "llama-3-8b"
    training_date: datetime
    training_dataset_path: str  # S3 path
    training_dataset_size: int
    
    # M√©tricas de Performance
    performance_metrics: Dict[str, float]  # F1, precision, recall
    performance_by_slice: Dict[str, Dict[str, float]]  # Por tipo de documento, dom√≠nio, etc.
    
    # An√°lise de Vi√©s
    bias_analysis: Optional[Dict[str, float]]  # M√©tricas de Fairlearn, etc.
    
    # Limita√ß√µes Conhecidas
    known_limitations: List[str]
    intended_use_cases: List[str]
    
    # Linhagem
    parent_model_id: Optional[str]  # Modelo anterior (se houver)
    fine_tuning_hyperparameters: Dict[str, any]
    
    def to_markdown(self) -> str:
        """Exporta Model Card para Markdown."""
        return f"""# Model Card: {self.model_name} v{self.version}

## Informa√ß√µes B√°sicas

- **Model ID:** {self.model_id}
- **Base Model:** {self.base_model}
- **Training Date:** {self.training_date.isoformat()}
- **Training Dataset:** {self.training_dataset_path} ({self.training_dataset_size} examples)

## M√©tricas de Performance

### M√©tricas Globais

- **F1-Score:** {self.performance_metrics.get('f1', 'N/A'):.3f}
- **Precision:** {self.performance_metrics.get('precision', 'N/A'):.3f}
- **Recall:** {self.performance_metrics.get('recall', 'N/A'):.3f}

### Performance por Slice

{self._format_performance_by_slice()}

## An√°lise de Vi√©s

{self._format_bias_analysis()}

## Limita√ß√µes Conhecidas

{chr(10).join(f'- {limitation}' for limitation in self.known_limitations)}

## Casos de Uso Pretendidos

{chr(10).join(f'- {use_case}' for use_case in self.intended_use_cases)}

## Linhagem

- **Parent Model:** {self.parent_model_id or 'None (base model)'}
- **Hyperparameters:** {json.dumps(self.fine_tuning_hyperparameters, indent=2)}
"""

class ModelCardService:
    """Service para criar e gerenciar Model Cards."""
    
    async def create_model_card(
        self,
        model_id: str,
        model_path: str,
        training_dataset_path: str,
        evaluation_results: Dict
    ) -> ModelCard:
        """
        Cria Model Card ap√≥s treinamento de modelo.
        """
        # Buscar informa√ß√µes do modelo
        model_info = await self._load_model_info(model_path)
        
        # Avaliar em slices de dados cr√≠ticos
        performance_by_slice = await self._evaluate_by_slice(model_path)
        
        # An√°lise de vi√©s
        bias_analysis = await self._analyze_bias(model_path)
        
        model_card = ModelCard(
            model_id=model_id,
            model_name=model_info["name"],
            version=model_info["version"],
            base_model=model_info["base_model"],
            training_date=datetime.utcnow(),
            training_dataset_path=training_dataset_path,
            training_dataset_size=evaluation_results["dataset_size"],
            performance_metrics=evaluation_results["metrics"],
            performance_by_slice=performance_by_slice,
            bias_analysis=bias_analysis,
            known_limitations=await self._identify_limitations(model_path),
            intended_use_cases=["Knowledge extraction from documents"],
            parent_model_id=evaluation_results.get("parent_model_id"),
            fine_tuning_hyperparameters=model_info["hyperparameters"]
        )
        
        # Salvar Model Card
        await self._save_model_card(model_card)
        
        return model_card
    
    async def _evaluate_by_slice(
        self,
        model_path: str
    ) -> Dict[str, Dict[str, float]]:
        """
        Avalia modelo em slices de dados cr√≠ticos.
        
        Slices:
        - Por tipo de documento (t√©cnico, legal, financeiro, etc.)
        - Por dom√≠nio (marketing, P&D, jur√≠dico)
        - Por tamanho de documento
        """
        slices = {
            "document_type": await self._evaluate_by_document_type(model_path),
            "domain": await self._evaluate_by_domain(model_path),
            "document_size": await self._evaluate_by_document_size(model_path)
        }
        
        return slices
```

#### 10.5.6.2 Linhagem de Extra√ß√£o

**Modelo de Dados para Rastreabilidade:**

```python
# backend/app/models/ontology.py (adicionar)
class ExtractionLineage(Base):
    """Linhagem de uma extra√ß√£o (qual modelo produziu qual dado)."""
    __tablename__ = "extraction_lineage"
    
    id = Column(UUID, primary_key=True, default=uuid4)
    extraction_id = Column(UUID, ForeignKey("extractions.id"))
    model_id = Column(String)  # ID do modelo usado
    model_version = Column(String)
    model_card_path = Column(String)  # Path para Model Card
    extraction_timestamp = Column(DateTime, server_default=func.now())
    
    # Metadata do modelo no momento da extra√ß√£o
    model_metadata = Column(JSONB)  # Hyperparameters, dataset usado, etc.

# Atualizar ExtractionValidation para incluir linhagem
class ExtractionValidation(Base):
    # ... campos existentes ...
    
    extraction_model_id = Column(String)  # ID do modelo que produziu a extra√ß√£o
    extraction_model_version = Column(String)
```

**Integra√ß√£o no Servi√ßo de Extra√ß√£o:**

```python
# backend/app/services/knowledge_extraction_service.py (atualizado)
class KnowledgeExtractionService:
    # ... c√≥digo anterior ...
    
    async def extract_from_document(
        self,
        document_content: str,
        model_id: str = None  # Modelo espec√≠fico (ou None para usar padr√£o)
    ) -> ExtractedKnowledge:
        """
        Extrai conhecimento e registra linhagem.
        """
        # Determinar modelo a usar
        if model_id is None:
            model_id = await self._get_current_production_model_id()
        
        model_info = await self._get_model_info(model_id)
        
        # Executar extra√ß√£o
        extracted = await self._execute_extraction(document_content, model_info)
        
        # Registrar linhagem
        lineage = ExtractionLineage(
            extraction_id=extracted.id,
            model_id=model_id,
            model_version=model_info["version"],
            model_card_path=model_info["model_card_path"],
            model_metadata={
                "base_model": model_info["base_model"],
                "training_date": model_info["training_date"],
                "dataset_path": model_info["training_dataset_path"]
            }
        )
        self.db.add(lineage)
        await self.db.commit()
        
        # Adicionar metadata de modelo ao resultado
        extracted.extraction_model_id = model_id
        extracted.extraction_model_version = model_info["version"]
        
        return extracted
```

#### 10.5.6.3 Su√≠te de Testes Comportamentais

**Framework de Testes Qualitativos:**

```python
# backend/tests/ontologies/test_model_behavior.py
import pytest
from checklist.test_types import MFT, INV, DIR  # Behavioral testing library
from typing import List, Dict

class ModelBehaviorTestSuite:
    """Su√≠te de testes comportamentais para modelos de extra√ß√£o."""
    
    def __init__(self, model: ExtractorModel):
        self.model = model
    
    def test_robustness_to_typos(self):
        """
        Testa robustez a typos comuns.
        
        O modelo deve extrair o mesmo conceito mesmo com typos.
        """
        test_cases = [
            ("Intelig√™ncia Artificial", "Inteligencia Artificial"),  # Sem acento
            ("Machine Learning", "Machine Learing"),  # Typo
            ("Deep Learning", "Deep Learing"),  # Typo
        ]
        
        for correct, typo in test_cases:
            original_extraction = self.model.extract(f"Documento sobre {correct}")
            typo_extraction = self.model.extract(f"Documento sobre {typo}")
            
            # Verificar que conceitos extra√≠dos s√£o similares
            assert self._concepts_similar(
                original_extraction.concepts,
                typo_extraction.concepts
            ), f"Model should be robust to typo: '{typo}'"
    
    def test_invariance_to_gender(self):
        """
        Testa invari√¢ncia a mudan√ßas de g√™nero em nomes.
        
        O modelo n√£o deve associar g√™nero a conceitos espec√≠ficos.
        """
        test_cases = [
            ("Jo√£o Silva trabalha com IA", "Maria Silva trabalha com IA"),
            ("Engenheiro desenvolveu sistema", "Engenheira desenvolveu sistema"),
        ]
        
        for male_text, female_text in test_cases:
            male_extraction = self.model.extract(male_text)
            female_extraction = self.model.extract(female_text)
            
            # Extra√ß√µes devem ser semanticamente equivalentes
            assert self._extractions_equivalent(
                male_extraction,
                female_extraction
            ), "Model should be invariant to gender"
    
    def test_negation_handling(self):
        """
        Testa capacidade de lidar com nega√ß√£o.
        
        "N√£o √© sobre IA" n√£o deve extrair "IA" como conceito principal.
        """
        positive_text = "Este documento √© sobre Intelig√™ncia Artificial"
        negative_text = "Este documento n√£o √© sobre Intelig√™ncia Artificial"
        
        positive_extraction = self.model.extract(positive_text)
        negative_extraction = self.model.extract(negative_text)
        
        # Texto negativo n√£o deve ter "IA" como conceito principal
        ia_concept_positive = any(
            "intelig√™ncia artificial" in c.label.lower()
            for c in positive_extraction.concepts
        )
        ia_concept_negative = any(
            "intelig√™ncia artificial" in c.label.lower()
            for c in negative_extraction.concepts
        )
        
        assert ia_concept_positive, "Positive text should extract IA"
        # Nega√ß√£o pode ainda extrair IA, mas com menor confian√ßa ou como conceito secund√°rio
        # (depende da estrat√©gia - aqui √© um exemplo simplificado)
    
    def test_known_failure_cases(self):
        """
        Testa casos de falha conhecidos de vers√µes anteriores.
        
        Garante que regress√µes n√£o s√£o introduzidas.
        """
        known_failures = [
            {
                "input": "Documento sobre projeto de pesquisa em IA",
                "expected_concepts": ["Intelig√™ncia Artificial", "Pesquisa"],
                "previous_failure": "N√£o extra√≠a 'Pesquisa' como conceito"
            },
            # Adicionar mais casos conhecidos
        ]
        
        for case in known_failures:
            extraction = self.model.extract(case["input"])
            extracted_concepts = [c.label for c in extraction.concepts]
            
            for expected in case["expected_concepts"]:
                assert any(
                    expected.lower() in c.lower() for c in extracted_concepts
                ), f"Known failure case not fixed: {case['previous_failure']}"

# Testes pytest
@pytest.mark.behavior
def test_model_behavior_suite(current_extraction_model):
    """Executa su√≠te completa de testes comportamentais."""
    suite = ModelBehaviorTestSuite(current_extraction_model)
    
    suite.test_robustness_to_typos()
    suite.test_invariance_to_gender()
    suite.test_negation_handling()
    suite.test_known_failure_cases()
```

#### 10.5.6.4 Explainability no Dashboard

**Integra√ß√£o de SHAP/LIME no Dashboard:**

```python
# backend/app/services/explainability_service.py
import shap
import lime
from lime.lime_text import LimeTextExplainer
from typing import List, Dict

class ExplainabilityService:
    """Service para explicabilidade de extra√ß√µes."""
    
    def __init__(self, model: ExtractorModel):
        self.model = model
        self.explainer = LimeTextExplainer(class_names=["entities", "concepts", "relations"])
    
    async def explain_extraction(
        self,
        document_text: str,
        extracted_entity: Entity
    ) -> ExtractionExplanation:
        """
        Explica por que uma entidade foi extra√≠da.
        
        Retorna quais palavras no texto mais influenciaram a extra√ß√£o.
        """
        # Usar LIME para explica√ß√£o
        explanation = self.explainer.explain_instance(
            document_text,
            lambda x: self._predict_entity_probability(x, extracted_entity),
            num_features=10  # Top 10 palavras mais influentes
        )
        
        # Extrair features mais importantes
        important_words = explanation.as_list()
        
        return ExtractionExplanation(
            entity_id=extracted_entity.id,
            entity_label=extracted_entity.label,
            important_words=important_words,  # Lista de (palavra, import√¢ncia)
            explanation_html=explanation.as_html(),
            confidence=extracted_entity.confidence
        )
    
    def _predict_entity_probability(
        self,
        text_variations: List[str],
        target_entity: Entity
    ) -> List[float]:
        """
        Prediz probabilidade de extrair entidade para varia√ß√µes de texto.
        
        Usado pelo LIME.
        """
        probabilities = []
        for text in text_variations:
            extraction = self.model.extract(text)
            # Verificar se target_entity est√° presente
            entity_present = any(
                target_entity.label.lower() in e.label.lower()
                for e in extraction.entities
            )
            probabilities.append(1.0 if entity_present else 0.0)
        
        return probabilities

# Endpoint para explicabilidade
@router.get("/extractions/{extraction_id}/explain/{entity_id}")
async def explain_entity_extraction(
    extraction_id: UUID,
    entity_id: UUID
) -> ExtractionExplanationResponse:
    """
    Explica por que uma entidade espec√≠fica foi extra√≠da.
    
    Retorna palavras-chave que influenciaram a extra√ß√£o.
    """
    extraction = await extraction_repository.get_by_id(extraction_id)
    entity = next(e for e in extraction.entities if e.id == entity_id)
    
    explainability_service = ExplainabilityService(current_model)
    explanation = await explainability_service.explain_extraction(
        extraction.document_content,
        entity
    )
    
    return ExtractionExplanationResponse(
        entity_label=explanation.entity_label,
        important_words=explanation.important_words,
        explanation_html=explanation.explanation_html,
        confidence=explanation.confidence
    )
```

#### 10.5.6.5 Processo de Deploy com Governan√ßa

**Pipeline de Deploy com Valida√ß√µes:**

```python
# backend/app/workers/fine_tuning_worker.py (atualizado)
@app.task
async def periodic_fine_tuning_with_governance():
    """
    Fine-tuning peri√≥dico com valida√ß√µes de governan√ßa.
    """
    fine_tuning_service = FineTuningService()
    model_card_service = ModelCardService()
    behavior_test_suite = ModelBehaviorTestSuite()
    
    # 1. Exportar dataset
    dataset = await fine_tuning_service.export_training_dataset(min_validations=500)
    
    # 2. Treinar modelo
    model_path = await train_model(dataset)
    
    # 3. Avaliar m√©tricas globais
    evaluation_metrics = await evaluate_model(model_path)
    
    # 4. Criar Model Card
    model_card = await model_card_service.create_model_card(
        model_id=f"extraction-model-{datetime.now().strftime('%Y%m%d')}",
        model_path=model_path,
        training_dataset_path=dataset.path,
        evaluation_results={
            "dataset_size": dataset.examples_count,
            "metrics": evaluation_metrics
        }
    )
    
    # 5. Executar testes comportamentais
    behavior_results = await behavior_test_suite.run_all_tests(model_path)
    
    # 6. Valida√ß√µes de deploy
    deploy_approved = await _validate_deploy(
        evaluation_metrics,
        behavior_results,
        model_card
    )
    
    if deploy_approved:
        # 7. Deploy do modelo
        await deploy_model(model_path, version="v2", model_card=model_card)
        logger.info(f"Deployed model with governance: {model_card.model_id}")
    else:
        logger.warning("Model deployment rejected by governance checks")
    
    return {
        "model_id": model_card.model_id,
        "metrics": evaluation_metrics,
        "behavior_tests": behavior_results,
        "deployed": deploy_approved
    }

async def _validate_deploy(
    evaluation_metrics: Dict,
    behavior_results: Dict,
    model_card: ModelCard
) -> bool:
    """
    Valida se modelo deve ser deployado.
    
    Checks:
    - M√©tricas melhoraram (>5% F1)
    - Testes comportamentais passaram
    - Sem vieses cr√≠ticos detectados
    - Model Card completo
    """
    # Check 1: Melhoria de m√©tricas
    current_f1 = await get_current_production_f1()
    new_f1 = evaluation_metrics["f1"]
    if new_f1 <= current_f1 * 1.05:
        logger.warning("F1 improvement < 5%. Deployment rejected.")
        return False
    
    # Check 2: Testes comportamentais
    if not behavior_results["all_passed"]:
        logger.warning("Behavioral tests failed. Deployment rejected.")
        return False
    
    # Check 3: Vi√©s cr√≠tico
    if model_card.bias_analysis:
        critical_bias = any(
            score > 0.2  # Limiar de vi√©s cr√≠tico
            for score in model_card.bias_analysis.values()
        )
        if critical_bias:
            logger.warning("Critical bias detected. Deployment rejected.")
            return False
    
    # Check 4: Model Card completo
    if not model_card.known_limitations:
        logger.warning("Model Card incomplete. Deployment rejected.")
        return False
    
    return True
```

### 10.5.6.6 Benef√≠cios do Framework de MLOps

**Auditabilidade:**
- Rastreabilidade completa de qual modelo produziu qual dado
- Model Cards documentam decis√µes e limita√ß√µes

**Seguran√ßa e Justi√ßa:**
- Detec√ß√£o de vieses atrav√©s de an√°lise e testes comportamentais
- Preven√ß√£o de regress√µes atrav√©s de testes conhecidos

**Confian√ßa:**
- Explicabilidade permite depura√ß√£o e compreens√£o
- Transpar√™ncia aumenta confian√ßa dos stakeholders

**Riscos Mitigados:**
- ‚úÖ **Caixa-Preta:** Transformado em sistema explic√°vel e audit√°vel
- ‚úÖ **Vieses Sutis:** Detectados atrav√©s de an√°lise e testes comportamentais
- ‚úÖ **Rastreabilidade:** Linhagem completa de extra√ß√µes
- ‚úÖ **Deploy N√£o-Governado:** Pipeline de valida√ß√£o antes do deploy

---

**Benef√≠cios do Framework de Curadoria Ativa:**

- ‚úÖ **Efici√™ncia Humana:** Maximiza impacto do tempo limitado do especialista
- ‚úÖ **Sistema que Aprende:** Cria ciclo virtuoso onde sistema fica mais inteligente
- ‚úÖ **Engajamento:** Transforma tarefa tediosa em parte integrada e recompensada
- ‚úÖ **Redu√ß√£o de Custos:** Fine-tuning reduz depend√™ncia de GPT-4 ao longo do tempo
- ‚úÖ **Qualidade Crescente:** Sistema melhora continuamente com feedback humano

### 10.6 Monitoramento de Concept Drift Sem√¢ntico

> **üü° Cr√≠tica N√≠vel 2 Aplicada:** Implementa√ß√£o de detec√ß√£o proativa de concept drift para garantir que o Knowledge Graph continue sendo um reflexo fiel da realidade ao longo do tempo, mesmo quando a estrutura da ontologia n√£o muda.

**O Problema Original:** O plano √© excepcional em gerenciar o *versionamento* da ontologia, mas n√£o possui um mecanismo para *detectar* quando a pr√≥pria *realidade* que a ontologia descreve mudou. O significado de "IA Respons√°vel" em 2025 pode ser diferente de 2028. Este fen√¥meno √© conhecido como **concept drift**.

**Por Que Importa:**
- Com o tempo, o Knowledge Graph se torna uma representa√ß√£o defasada da realidade
- As extra√ß√µes podem continuar sendo sintaticamente corretas, mas semanticamente erradas
- Leva a insights incorretos de forma silenciosa

**A Solu√ß√£o: Servi√ßo de Detec√ß√£o de Concept Drift Sem√¢ntico**

### 10.6.1 Armazenamento de Embeddings de Contexto

**Modelo de Dados:**

```python
# backend/app/models/ontology.py (adicionar)
class ConceptContext(Base):
    """Contexto de onde um conceito foi extra√≠do (para c√°lculo de drift)."""
    __tablename__ = "concept_contexts"
    
    id = Column(UUID, primary_key=True, default=uuid4)
    concept_id = Column(UUID, ForeignKey("knowledge_graph_concepts.id"))
    document_id = Column(UUID, ForeignKey("documents.id"))
    context_text = Column(Text)  # Par√°grafo/senten√ßa de origem
    context_embedding = Column(Vector(384))  # Embedding do contexto (all-MiniLM-L6-v2)
    extracted_at = Column(DateTime, server_default=func.now())
    
    # √çndice para busca por embedding
    __table_args__ = (
        Index('idx_concept_context_embedding', 'context_embedding', postgresql_using='ivfflat'),
    )

class ConceptCentroid(Base):
    """Centr√≥ide sem√¢ntico de um conceito (m√©dia dos embeddings de contexto)."""
    __tablename__ = "concept_centroids"
    
    concept_id = Column(UUID, ForeignKey("knowledge_graph_concepts.id"), primary_key=True)
    centroid_embedding = Column(Vector(384))  # Embedding m√©dio hist√≥rico
    contexts_count = Column(Integer, default=0)  # N√∫mero de contextos usados
    last_updated = Column(DateTime, server_default=func.now())
    drift_threshold = Column(Float, default=0.15)  # Limiar para alerta de drift
```

### 10.6.2 C√°lculo de Centr√≥ide Sem√¢ntico

**Servi√ßo de C√°lculo de Centr√≥ide:**

```python
# backend/app/services/concept_drift_service.py
from sentence_transformers import SentenceTransformer
import numpy as np
from typing import List, Tuple
import logging

logger = logging.getLogger(__name__)

class ConceptDriftService:
    """Service para detec√ß√£o de concept drift sem√¢ntico."""
    
    def __init__(self, db: AsyncSession, kg_repository: KnowledgeGraphRepository):
        self.db = db
        self.kg_repository = kg_repository
        self.model = SentenceTransformer('all-MiniLM-L6-v2')
        self.drift_threshold = 0.15  # Limiar padr√£o (ajust√°vel por conceito)
    
    async def store_concept_context(
        self,
        concept_id: UUID,
        document_id: UUID,
        context_text: str
    ):
        """
        Armazena contexto de onde um conceito foi extra√≠do.
        
        Usado para c√°lculo futuro de drift sem√¢ntico.
        """
        # Gerar embedding do contexto
        context_embedding = self.model.encode(context_text).tolist()
        
        # Salvar contexto
        context = ConceptContext(
            concept_id=concept_id,
            document_id=document_id,
            context_text=context_text,
            context_embedding=context_embedding
        )
        self.db.add(context)
        await self.db.commit()
        
        logger.debug(f"Stored context for concept {concept_id}")
    
    async def update_centroid(
        self,
        concept_id: UUID,
        include_recent: bool = True
    ) -> Tuple[np.ndarray, int]:
        """
        Atualiza o centr√≥ide sem√¢ntico de um conceito.
        
        Calcula a m√©dia dos embeddings de todos os contextos hist√≥ricos
        (ou apenas contextos recentes se include_recent=False).
        """
        # Buscar todos os contextos do conceito
        contexts = await self.db.execute(
            select(ConceptContext)
            .where(ConceptContext.concept_id == concept_id)
        )
        contexts = contexts.scalars().all()
        
        if not contexts:
            logger.warning(f"No contexts found for concept {concept_id}")
            return None, 0
        
        # Converter embeddings para numpy array
        embeddings = np.array([ctx.context_embedding for ctx in contexts])
        
        # Calcular centr√≥ide (m√©dia)
        centroid = np.mean(embeddings, axis=0)
        contexts_count = len(contexts)
        
        # Atualizar ou criar registro de centr√≥ide
        centroid_record = await self.db.get(ConceptCentroid, concept_id)
        if centroid_record:
            centroid_record.centroid_embedding = centroid.tolist()
            centroid_record.contexts_count = contexts_count
            centroid_record.last_updated = func.now()
        else:
            centroid_record = ConceptCentroid(
                concept_id=concept_id,
                centroid_embedding=centroid.tolist(),
                contexts_count=contexts_count
            )
            self.db.add(centroid_record)
        
        await self.db.commit()
        
        logger.info(
            f"Updated centroid for concept {concept_id} "
            f"(based on {contexts_count} contexts)"
        )
        
        return centroid, contexts_count
    
    def cosine_distance(self, embedding1: np.ndarray, embedding2: np.ndarray) -> float:
        """
        Calcula dist√¢ncia de cosseno entre dois embeddings.
        
        Returns:
            Dist√¢ncia (0 = id√™nticos, 1 = ortogonais, 2 = opostos)
        """
        # Normalizar embeddings
        norm1 = np.linalg.norm(embedding1)
        norm2 = np.linalg.norm(embedding2)
        
        if norm1 == 0 or norm2 == 0:
            return 1.0  # M√°xima dist√¢ncia
        
        # Produto escalar normalizado (cosseno de similaridade)
        cosine_sim = np.dot(embedding1, embedding2) / (norm1 * norm2)
        
        # Converter para dist√¢ncia (1 - similaridade)
        distance = 1 - cosine_sim
        
        return distance
```

### 10.6.3 Servi√ßo de Monitoramento de Drift

**Worker Peri√≥dico para Detec√ß√£o de Drift:**

```python
# backend/app/workers/concept_drift_worker.py
from datetime import datetime, timedelta
import numpy as np
from typing import List
import logging

logger = logging.getLogger(__name__)

class ConceptDriftWorker:
    """Worker para detectar concept drift sem√¢ntico."""
    
    def __init__(
        self,
        concept_drift_service: ConceptDriftService,
        validation_repository
    ):
        self.concept_drift_service = concept_drift_service
        self.validation_repository = validation_repository
        self.drift_threshold = 0.15  # Limiar padr√£o
    
    async def check_concept_drift(
        self,
        lookback_period_days: int = 90
    ) -> List[DriftAlert]:
        """
        Verifica drift sem√¢ntico para todos os conceitos.
        
        Args:
            lookback_period_days: Per√≠odo para considerar contextos "recentes" (padr√£o: 90 dias)
        
        Returns:
            Lista de alertas de drift detectados
        """
        cutoff_date = datetime.utcnow() - timedelta(days=lookback_period_days)
        
        # Buscar todos os conceitos com centr√≥ides
        concepts_with_centroids = await self._get_concepts_with_centroids()
        
        drift_alerts = []
        
        for concept in concepts_with_centroids:
            # Buscar contextos recentes
            recent_contexts = await self._get_recent_contexts(
                concept.id,
                cutoff_date
            )
            
            if len(recent_contexts) < 10:  # M√≠nimo de contextos para an√°lise
                logger.debug(
                    f"Concept {concept.label} has only {len(recent_contexts)} "
                    f"recent contexts. Skipping drift check."
                )
                continue
            
            # Calcular novo centr√≥ide dos contextos recentes
            recent_embeddings = np.array([ctx.context_embedding for ctx in recent_contexts])
            new_centroid = np.mean(recent_embeddings, axis=0)
            
            # Comparar com centr√≥ide hist√≥rico
            historic_centroid = np.array(concept.centroid_embedding)
            drift_distance = self.concept_drift_service.cosine_distance(
                historic_centroid,
                new_centroid
            )
            
            # Verificar se excede limiar
            threshold = concept.drift_threshold or self.drift_threshold
            if drift_distance > threshold:
                # Criar alerta de drift
                alert = await self._create_drift_alert(
                    concept_id=concept.id,
                    concept_label=concept.label,
                    drift_score=drift_distance,
                    threshold=threshold,
                    recent_contexts_count=len(recent_contexts),
                    message=(
                        f"O significado de '{concept.label}' pode ter mudado. "
                        f"Drift detectado: {drift_distance:.3f} (threshold: {threshold:.3f})"
                    )
                )
                drift_alerts.append(alert)
                
                logger.warning(
                    f"Concept drift detected for '{concept.label}': "
                    f"{drift_distance:.3f} > {threshold:.3f}"
                )
        
        return drift_alerts
    
    async def _create_drift_alert(
        self,
        concept_id: UUID,
        concept_label: str,
        drift_score: float,
        threshold: float,
        recent_contexts_count: int,
        message: str
    ) -> DriftAlert:
        """Cria alerta de drift no sistema de valida√ß√£o."""
        alert = DriftAlert(
            concept_id=concept_id,
            concept_label=concept_label,
            drift_score=drift_score,
            threshold=threshold,
            contexts_count=recent_contexts_count,
            message=message,
            detected_at=datetime.utcnow(),
            status="pending_review"  # Requer revis√£o humana
        )
        
        # Salvar alerta
        self.db.add(alert)
        await self.db.commit()
        
        # Notificar no dashboard de valida√ß√£o (alta prioridade)
        await self.validation_repository.create_validation_task(
            task_type="concept_drift_review",
            concept_id=concept_id,
            priority_score=0.9,  # Alta prioridade
            metadata={
                "drift_score": drift_score,
                "threshold": threshold,
                "contexts_count": recent_contexts_count
            }
        )
        
        return alert

# Worker peri√≥dico (Celery/RQ)
@app.task
async def periodic_concept_drift_check():
    """
    Tarefa peri√≥dica (mensal/trimestral) para verificar concept drift.
    
    Roda no primeiro dia de cada m√™s.
    """
    logger.info("Starting periodic concept drift check...")
    
    worker = ConceptDriftWorker(
        concept_drift_service=ConceptDriftService(...),
        validation_repository=ValidationRepository(...)
    )
    
    alerts = await worker.check_concept_drift(lookback_period_days=90)
    
    logger.info(f"Concept drift check completed. {len(alerts)} alerts created.")
    
    return {
        "alerts_count": len(alerts),
        "alerts": [alert.id for alert in alerts]
    }
```

### 10.6.4 Integra√ß√£o com Pipeline de Extra√ß√£o

**Armazenar Contexto Durante Extra√ß√£o:**

```python
# backend/app/services/ontology_service.py (atualizado)
class OntologyService:
    # ... c√≥digo anterior ...
    
    async def process_document_ontology(
        self,
        document_id: UUID,
        document_content: str
    ) -> ProcessedOntology:
        # ... extra√ß√£o e processamento existente ...
        
        # NOVO: Armazenar contextos para cada conceito extra√≠do
        concept_drift_service = ConceptDriftService(self.db, self.kg_repository)
        
        for concept in validated.concepts:
            # Extrair contexto (par√°grafo onde conceito aparece)
            context_text = self._extract_concept_context(
                document_content,
                concept.label
            )
            
            # Armazenar contexto com embedding
            await concept_drift_service.store_concept_context(
                concept_id=concept.id,
                document_id=document_id,
                context_text=context_text
            )
        
        # ... resto do processamento ...
    
    def _extract_concept_context(
        self,
        document_content: str,
        concept_label: str,
        context_window: int = 200
    ) -> str:
        """
        Extrai contexto (par√°grafo/senten√ßa) onde um conceito aparece.
        
        Args:
            document_content: Conte√∫do completo do documento
            concept_label: Label do conceito a localizar
            context_window: N√∫mero de caracteres ao redor do conceito
        
        Returns:
            Texto do contexto
        """
        # Localizar primeira ocorr√™ncia do conceito
        index = document_content.lower().find(concept_label.lower())
        
        if index == -1:
            # Conceito n√£o encontrado no texto (pode ter sido inferido)
            return document_content[:context_window]  # Retornar in√≠cio
        
        # Extrair contexto ao redor
        start = max(0, index - context_window // 2)
        end = min(len(document_content), index + len(concept_label) + context_window // 2)
        
        context = document_content[start:end]
        
        # Garantir que come√ßa e termina em palavras completas
        context = context.strip()
        if not context.startswith(concept_label):
            # Tentar encontrar in√≠cio de palavra/senten√ßa
            first_space = context.find(' ')
            if first_space > 0:
                context = context[first_space+1:]
        
        return context
```

### 10.6.5 Dashboard de Alertas de Drift

**Interface para Visualiza√ß√£o de Drift:**

```python
# backend/app/api/v1/endpoints/concept_drift.py
@router.get("/concept-drift/alerts")
async def get_drift_alerts(
    status: str = "pending_review",
    min_score: float = 0.15
) -> List[DriftAlertResponse]:
    """
    Retorna alertas de concept drift pendentes de revis√£o.
    """
    alerts = await drift_repository.get_alerts(
        status=status,
        min_score=min_score
    )
    
    return [
        DriftAlertResponse(
            id=alert.id,
            concept_id=alert.concept_id,
            concept_label=alert.concept_label,
            drift_score=alert.drift_score,
            threshold=alert.threshold,
            contexts_count=alert.contexts_count,
            message=alert.message,
            detected_at=alert.detected_at,
            status=alert.status
        )
        for alert in alerts
    ]

@router.post("/concept-drift/alerts/{alert_id}/resolve")
async def resolve_drift_alert(
    alert_id: UUID,
    action: DriftResolutionAction,
    notes: str = None
):
    """
    Resolve um alerta de drift.
    
    Actions:
    - "update_ontology": Conceito mudou - atualizar ontologia
    - "update_centroid": Significado mudou - atualizar centr√≥ide
    - "false_positive": Falso positivo - manter como est√°
    """
    alert = await drift_repository.get_alert(alert_id)
    
    if action == "update_centroid":
        # Atualizar centr√≥ide hist√≥rico com novos contextos
        await concept_drift_service.update_centroid(alert.concept_id)
        alert.status = "resolved"
        alert.resolution_action = "centroid_updated"
    
    elif action == "update_ontology":
        # Criar task para atualizar ontologia (requer revis√£o)
        await ontology_repository.create_update_task(
            concept_id=alert.concept_id,
            reason="concept_drift",
            notes=notes
        )
        alert.status = "resolved"
        alert.resolution_action = "ontology_update_requested"
    
    elif action == "false_positive":
        alert.status = "resolved"
        alert.resolution_action = "false_positive"
    
    alert.resolved_at = datetime.utcnow()
    alert.resolution_notes = notes
    
    await drift_repository.save(alert)
    
    return {"status": "resolved", "alert_id": str(alert_id)}
```

### 10.6.6 Benef√≠cios do Monitoramento de Concept Drift

**Manuten√ß√£o Proativa:**
- Sistema avisa quando ontologia est√° ficando obsoleta
- Detecta mudan√ßas sem√¢nticas antes que causem problemas

**Governan√ßa Orientada a Dados:**
- Revis√µes da ontologia acionadas por evid√™ncias quantitativas
- N√£o depende apenas de intui√ß√£o humana

**Sustentabilidade de Longo Prazo:**
- Garante que KG continue sendo reflexo fiel da realidade
- Mant√©m qualidade sem√¢ntica ao longo do tempo

**Riscos Mitigados:**
- ‚úÖ **Degrada√ß√£o Silenciosa:** Detectada proativamente atrav√©s de drift scoring
- ‚úÖ **Insights Incorretos:** Prevenidos atrav√©s de alertas e revis√£o
- ‚úÖ **Ontologia Obsoleta:** Atualizada baseada em evid√™ncias de mudan√ßa sem√¢ntica

---

## üéØ Conclus√£o

Este plano de gest√£o de ontologias fornece uma **estrutura completa e pr√°tica** para:

1. ‚úÖ **Organizar** ontologias de forma modular
2. ‚úÖ **Versionar** com controle expl√≠cito
3. ‚úÖ **Automatizar** extra√ß√£o e compila√ß√£o
4. ‚úÖ **Integrar** com sistema existente
5. ‚úÖ **Evoluir** baseado em casos de uso
6. ‚úÖ **Documentar** decis√µes e mudan√ßas

A estrat√©gia √© **incremental**, permitindo come√ßar simples e evoluir gradualmente, sempre validando contra casos de uso reais.

---

**Pr√≥ximos Passos:**
1. Implementar estrutura de diret√≥rios
2. Criar schemas LinkML base
3. Integrar OntoGPT **com fallback (spaCy)**
4. Implementar deduplica√ß√£o de entidades
5. Criar testes de compet√™ncia
6. Testar com documentos reais
7. Iterar baseado em feedback

---

## üîÑ Melhorias Implementadas

### v1.1.0 - Melhorias de Engenharia

Este documento foi atualizado com **6 melhorias cr√≠ticas** baseadas em an√°lise de engenharia:

1. ‚úÖ **Estrat√©gia de Fallback para Extrator** (Se√ß√£o 6.1)
   - spaCy como fallback quando OntoGPT falha
   - Alta disponibilidade e degrada√ß√£o graciosa

2. ‚úÖ **Resolu√ß√£o e Deduplica√ß√£o de Entidades** (Se√ß√£o 6.4)
   - Embeddings de similaridade para evitar duplicatas
   - Knowledge Graph limpo e conectado

3. ‚úÖ **Testes de Compet√™ncia Automatizados** (Se√ß√£o 5.2)
   - Testes conectados √†s perguntas de compet√™ncia
   - Valida√ß√£o cont√≠nua e regress√£o automatizada

4. ‚úÖ **Dashboard de Valida√ß√£o Humana** (Se√ß√£o 10.5)
   - Interface para valida√ß√£o humana de extra√ß√µes
   - Feedback loop para melhoria cont√≠nua

5. ‚úÖ **Testes de Performance** (Se√ß√£o 10.4)
   - Pipeline de testes de performance
   - Detec√ß√£o de regress√µes antes da produ√ß√£o

6. ‚úÖ **An√°lise de Custo e Monitoramento** (Se√ß√£o 10.3)
   - Logging de custos de API
   - Dashboard de monitoramento
   - Alertas de or√ßamento

### v1.2.0 - Melhorias Cr√≠ticas de Red Team

Este documento foi atualizado com **3 melhorias cr√≠ticas** baseadas em an√°lise de Red Team (riscos estrat√©gicos e operacionais):

7. ‚úÖ **Sincroniza√ß√£o Resiliente com Padr√£o Outbox** (Se√ß√£o 4.2) ‚≠ê‚≠ê
   - Padr√£o Outbox/Saga para consist√™ncia eventual
   - Resili√™ncia a falhas do Neo4j
   - Worker ass√≠ncrono para sincroniza√ß√£o idempotente
   - **Resolve:** Calcanhar de Aquiles da Sincroniza√ß√£o

8. ‚úÖ **Experi√™ncia do Usu√°rio e Ciclo de Feedback** (Nova Se√ß√£o 7) ‚≠ê‚≠ê
   - Mockups de UI e funcionalidades vis√≠veis
   - Fluxo completo de feedback do usu√°rio
   - M√©tricas de valor de neg√≥cio (n√£o apenas t√©cnicas)
   - Killer features habilitadas pela arquitetura
   - **Resolve:** Paradoxo da Complexidade vs. Valor

9. ‚úÖ **Framework de Curadoria Ativa** (Se√ß√£o 10.5 expandida) ‚≠ê‚≠ê
   - Aprendizado Ativo para prioriza√ß√£o inteligente
   - Gamifica√ß√£o e sistema de incentivos
   - Integra√ß√£o ao fluxo de trabalho
   - Fine-tuning peri√≥dico baseado em feedback
   - **Resolve:** Ilus√£o do "Humano no Loop"

**Impacto das Melhorias v1.2.0:**

- üî¥ **Risco Estrat√©gico Mitigado:** Valor de neg√≥cio expl√≠cito e mensur√°vel
- üî¥ **Risco Arquitetural Mitigado:** Sincroniza√ß√£o resiliente e consistente
- üî¥ **Risco Operacional Mitigado:** Framework operacional para curadoria humana

### v1.3.0 - Melhorias Cr√≠ticas de Red Team N√≠vel 2

Este documento foi atualizado com **3 melhorias cr√≠ticas de segunda ordem** baseadas em an√°lise de Red Team N√≠vel 2 (riscos de longo prazo, escala organizacional e sustentabilidade):

10. ‚úÖ **Governan√ßa Federada em Escala** (Nova Se√ß√£o 11) ‚≠ê‚≠ê‚≠ê
    - Arquitetura de ontologia federada (semantic data mesh)
    - M√∫ltiplos reposit√≥rios de ontologia por dom√≠nio
    - Servi√ßo de registro de ontologias (OntologyRegistry)
    - Heran√ßa expl√≠cita e resolu√ß√£o de conflitos de namespace
    - **Resolve:** Fal√°cia do "C√©rebro √önico" - gargalo de governan√ßa centralizada

11. ‚úÖ **Monitoramento de Concept Drift Sem√¢ntico** (Nova Se√ß√£o 10.6) ‚≠ê‚≠ê‚≠ê
    - Detec√ß√£o proativa de mudan√ßas sem√¢nticas ao longo do tempo
    - Armazenamento de embeddings de contexto
    - C√°lculo de centr√≥ides sem√¢nticos
    - Worker peri√≥dico para detec√ß√£o de drift
    - Dashboard de alertas e resolu√ß√£o
    - **Resolve:** Pressuposi√ß√£o do "Mundo Est√°tico" - degrada√ß√£o silenciosa do KG

12. ‚úÖ **MLOps e Governan√ßa de Modelos** (Se√ß√£o 10.5.6 expandida) ‚≠ê‚≠ê‚≠ê
    - Model Cards para documenta√ß√£o e governan√ßa
    - Linhagem de extra√ß√£o (rastreabilidade completa)
    - Su√≠te de testes comportamentais (robustez, invari√¢ncia, nega√ß√£o)
    - Explainability no dashboard (SHAP/LIME)
    - Pipeline de deploy com valida√ß√µes de governan√ßa
    - **Resolve:** Caixa-Preta do Fine-Tuning - auditabilidade e explicabilidade

**Impacto das Melhorias v1.3.0:**

- üî¥ **Risco de Escala Organizacional Mitigado:** Governan√ßa federada permite crescimento sem gargalos
- üî¥ **Risco de Degrada√ß√£o Silenciosa Mitigado:** Concept drift detectado proativamente
- üî¥ **Risco de Caixa-Preta Mitigado:** Modelos explic√°veis, audit√°veis e governados
- ‚úÖ **Sustentabilidade de Longo Prazo:** Sistema projetado para evolu√ß√£o cont√≠nua e manuten√ß√£o proativa
- ‚úÖ **Capacidade Organizacional:** Transforma sistema t√©cnico em capacidade estrat√©gica de gest√£o de conhecimento

---

**Documento criado em:** 30 de Dezembro de 2025  
**Vers√£o:** 1.3.0 (atualizada com melhorias cr√≠ticas de Red Team N√≠vel 2)  
**Pr√≥xima revis√£o:** Ap√≥s implementa√ß√£o da Fase 1

---

## üìù Notas Finais sobre as Cr√≠ticas Aplicadas

Este plano evoluiu de um **documento de implementa√ß√£o t√©cnica** para um **plano de sistema sociot√©cnico de IA de classe mundial**, abordando proativamente:

1. ‚úÖ **Valor de Neg√≥cio Expl√≠cito:** Conex√£o clara entre arquitetura e experi√™ncia do usu√°rio
2. ‚úÖ **Resili√™ncia Arquitetural:** Padr√£o Outbox garante consist√™ncia em ambiente distribu√≠do
3. ‚úÖ **Operacionaliza√ß√£o do Feedback:** Framework de Curadoria Ativa resolve o problema humano
4. ‚úÖ **Escalabilidade Organizacional:** Governan√ßa federada permite crescimento sem gargalos
5. ‚úÖ **Sustentabilidade de Longo Prazo:** Detec√ß√£o proativa de concept drift mant√©m qualidade sem√¢ntica
6. ‚úÖ **Governan√ßa de IA:** MLOps e explicabilidade transformam caixa-preta em sistema audit√°vel

Os maiores desafios em IA n√£o s√£o puramente t√©cnicos, mas residem na **intersec√ß√£o da tecnologia com processos humanos, valor de neg√≥cio e sustentabilidade organizacional**. Este plano agora os aborda de forma integrada, projetando n√£o apenas para o lan√ßamento, mas para o sucesso, escala e sustentabilidade em um horizonte de 3 a 5 anos.

**Evolu√ß√£o do Documento:**
- **v1.0.0:** Plano t√©cnico inicial de gest√£o de ontologias
- **v1.1.0:** Melhorias de engenharia (fallback, deduplica√ß√£o, testes, performance)
- **v1.2.0:** Melhorias cr√≠ticas de Red Team (sincroniza√ß√£o, UX, curadoria)
- **v1.3.0:** Melhorias cr√≠ticas de Red Team N√≠vel 2 (governan√ßa federada, concept drift, MLOps)

O plano agora representa uma **capacidade organizacional de gest√£o de conhecimento**, n√£o apenas um sistema de software.

