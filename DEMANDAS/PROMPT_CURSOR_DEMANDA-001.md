# PROMPT PARA CURSOR â€” DEMANDA-001: LLM Orchestrator v1

**VersÃ£o:** 1.0  
**Data:** 7 de Janeiro de 2026  
**Tipo:** Contrato de Resultado (nÃ£o soluÃ§Ã£o)

---

## ğŸ¯ OBJETIVO (RESULTADO ESPERADO)

Implementar aplicaÃ§Ã£o desktop macOS que permite **validaÃ§Ã£o cruzada de prompts com mÃºltiplas LLMs**.

**Governado por:** ENDFIRST_SPEC_EF-2026-001 (VALIDADA pelo CEO em 07/01/2026)

**ReferÃªncia canÃ´nica:** `/METODO/examples/ENDFIRST_SPEC_EF-2026-001_LLM_ORCHESTRATOR.md`

---

## ğŸ“‹ RESULTADO ESTRUTURAL (5 VERDADES)

**No final, deve ser verdade que:**

1. âœ… Consigo enviar um prompt para mÃºltiplas LLMs simultaneamente e receber respostas comparÃ¡veis
2. âœ… Consigo selecionar a melhor resposta entre as LLMs baseado em critÃ©rio prÃ³prio
3. âœ… A resposta selecionada passa por validaÃ§Ã£o cruzada de outras LLMs em ordem configurÃ¡vel
4. âœ… Reduzo erro e viÃ©s nas decisÃµes baseadas em LLMs atravÃ©s de validaÃ§Ã£o entre pares
5. âœ… Mantenho contexto preservado durante todo o fluxo de refinamento iterativo

---

## ğŸ”’ CRITÃ‰RIOS DE ACEITAÃ‡ÃƒO (VERIFICÃVEIS)

**A implementaÃ§Ã£o sÃ³ pode ser considerada DONE quando:**

- [ ] **CritÃ©rio 1:** Consigo enviar um prompt para 1-4 LLMs simultaneamente
  - **Teste:** Enviar para 2 LLMs e receber 2 respostas

- [ ] **CritÃ©rio 2:** Respostas sÃ£o exibidas lado a lado em interface visual
  - **Teste:** Ver 4 respostas na tela ao mesmo tempo

- [ ] **CritÃ©rio 3:** Consigo selecionar uma resposta como "melhor"
  - **Teste:** Clicar em resposta e ver marcaÃ§Ã£o visual

- [ ] **CritÃ©rio 4:** Resposta selecionada inicia validaÃ§Ã£o cruzada automaticamente
  - **Teste:** Selecionar e ver fluxo de revisÃ£o

- [ ] **CritÃ©rio 5:** Ordem de validaÃ§Ã£o muda baseada na LLM inicial
  - **Teste:** Selecionar ChatGPT e verificar ordem Geminiâ†’Manusâ†’Claude

- [ ] **CritÃ©rio 6:** Contexto Ã© preservado durante refinamentos
  - **Teste:** Fazer 3 rodadas de revisÃ£o e verificar que contexto anterior estÃ¡ presente

- [ ] **CritÃ©rio 7:** Sistema roda localmente no macOS
  - **Teste:** Abrir e usar sem conexÃ£o com servidor externo

---

## ğŸ¯ ESCOPO (DENTRO/FORA)

### âœ… Dentro do escopo (DEVE implementar)

- âœ”ï¸ Envio de prompt para mÃºltiplas LLMs (1-4) simultaneamente
- âœ”ï¸ ComparaÃ§Ã£o visual de respostas lado a lado
- âœ”ï¸ SeleÃ§Ã£o de melhor resposta (manual)
- âœ”ï¸ ValidaÃ§Ã£o cruzada automatizada (ordem configurÃ¡vel)
- âœ”ï¸ PreservaÃ§Ã£o de contexto durante refinamentos
- âœ”ï¸ ExecuÃ§Ã£o local (macOS)
- âœ”ï¸ Gerenciamento de APIs (cadastro, configuraÃ§Ã£o)
- âœ”ï¸ Interface visual intuitiva
- âœ”ï¸ Suporte para 4 LLMs (ChatGPT, Gemini, Manus, Claude)

### âŒ Fora do escopo (NÃƒO DEVE implementar)

- âŒ Suporte para Windows ou Linux
- âŒ Mais de 4 LLMs na versÃ£o inicial
- âŒ Treinamento de modelos prÃ³prios
- âŒ Hospedagem em nuvem
- âŒ Compartilhamento de conversas entre usuÃ¡rios
- âŒ IntegraÃ§Ã£o com outras ferramentas (Notion, Slack, etc.)
- âŒ AnÃ¡lise estatÃ­stica automÃ¡tica de qual LLM Ã© "melhor"
- âŒ SeleÃ§Ã£o automÃ¡tica de melhor resposta
- âŒ HistÃ³rico persistente de conversas
- âŒ Controle automÃ¡tico de custos

---

## ğŸš« ANTI-RESULTADOS (NÃƒO PODE ACONTECER)

**Mesmo se todos os critÃ©rios tÃ©cnicos passarem, NÃƒO PODE:**

- âŒ Sistema funciona, mas usuÃ¡rio nÃ£o confia nas respostas (falta transparÃªncia)
- âŒ ComparaÃ§Ã£o existe, mas nÃ£o ajuda a decidir (falta critÃ©rio de seleÃ§Ã£o)
- âŒ Processo automatizado existe, mas ninguÃ©m usa (complexidade excessiva)
- âŒ ValidaÃ§Ã£o cruzada existe, mas adiciona mais confusÃ£o que clareza
- âŒ Sistema reduz erro de LLM, mas introduz erro de orquestraÃ§Ã£o (bug no fluxo)

---

## ğŸŸ¡ INCERTEZAS ACEITÃVEIS (DECISÃ•ES PERMITIDAS)

### Incerteza 1: Stack tecnolÃ³gico exato
- âœ… **OK:** Escolher entre Electron+React, SwiftUI ou Tauri baseado em teste rÃ¡pido (< 2 dias)
- âŒ **NÃƒO OK:** Gastar mais de 2 dias decidindo stack sem prototipar

### Incerteza 2: UX/UI detalhado
- âœ… **OK:** ComeÃ§ar com wireframe simples e iterar baseado em uso real
- âŒ **NÃƒO OK:** Tentar criar interface "perfeita" antes de testar fluxo bÃ¡sico

### Incerteza 3: Gerenciamento de tokens/custos
- âœ… **OK:** VersÃ£o v1 nÃ£o controla custos automaticamente, apenas alerta
- âŒ **NÃƒO OK:** Ignorar completamente (deve estar no roadmap futuro)

### Incerteza 4: Performance com 4 LLMs simultÃ¢neas
- âœ… **OK:** Testar com casos reais e otimizar se necessÃ¡rio
- âŒ **NÃƒO OK:** Assumir que vai funcionar sem testar

### Incerteza 5: Formato de armazenamento de configuraÃ§Ãµes
- âœ… **OK:** Usar JSON simples no inÃ­cio e migrar depois se necessÃ¡rio
- âŒ **NÃƒO OK:** Criar banco de dados complexo antes de validar necessidade

### Incerteza 6: CritÃ©rios de seleÃ§Ã£o de "melhor resposta"
- âœ… **OK:** ComeÃ§ar com seleÃ§Ã£o manual e adicionar critÃ©rios depois baseado em uso
- âŒ **NÃƒO OK:** Tentar criar algoritmo de seleÃ§Ã£o automÃ¡tica antes de entender padrÃµes

### Incerteza 7: NÃºmero de LLMs suportadas
- âœ… **OK:** ComeÃ§ar com 4 LLMs e adicionar depois
- âŒ **NÃƒO OK:** Tentar suportar todas as LLMs do mercado desde o inÃ­cio

---

## ğŸ”— DEPENDÃŠNCIAS

### DependÃªncias tÃ©cnicas:
- APIs de ChatGPT, Gemini, Manus e Claude ativas e acessÃ­veis
- Credenciais/tokens de API configuradas e vÃ¡lidas
- macOS 12+ (sistema operacional)
- ConexÃ£o com internet (para chamadas de API)

### DependÃªncias organizacionais:
- OrÃ§amento para custos de APIs de LLMs
- AprovaÃ§Ã£o para uso de mÃºltiplas LLMs (se necessÃ¡rio)

---

## ğŸ“– ONTOLOGIA (TERMOS CRÃTICOS)

### "ValidaÃ§Ã£o cruzada"
Processo onde resposta selecionada Ã© enviada para outras LLMs em ordem configurÃ¡vel para validaÃ§Ã£o, refinamento e detecÃ§Ã£o de erro/viÃ©s.

### "Ordem configurÃ¡vel"
SequÃªncia de LLMs que recebem a resposta para validaÃ§Ã£o, determinada pela LLM inicial selecionada.

**Exemplo:**
- Se ChatGPT for selecionada â†’ Ordem: Gemini â†’ Manus â†’ Claude
- Se Gemini for selecionada â†’ Ordem: Manus â†’ Claude â†’ ChatGPT
- Se Manus for selecionada â†’ Ordem: Claude â†’ ChatGPT â†’ Gemini
- Se Claude for selecionada â†’ Ordem: ChatGPT â†’ Gemini â†’ Manus

### "Contexto preservado"
HistÃ³rico de prompts e respostas mantido durante todo o fluxo de refinamento, permitindo que LLMs subsequentes tenham acesso Ã s interaÃ§Ãµes anteriores.

---

## ğŸ›¡ï¸ ANTI-GAMING / INTEGRIDADE

**Como evitar que critÃ©rios sejam "passados" sem resultado real:**

- Sistema nÃ£o pode considerar "sucesso" se usuÃ¡rio nÃ£o interagiu com as respostas
- ValidaÃ§Ã£o cruzada nÃ£o pode ser considerada "completa" se LLMs nÃ£o receberam contexto anterior
- ComparaÃ§Ã£o lado a lado nÃ£o pode ser considerada "funcional" se respostas nÃ£o sÃ£o visÃ­veis simultaneamente

---

## ğŸ“‹ TAREFA (PASSO A PASSO)

### Passo 1: Definir stack tecnolÃ³gico (< 2 dias)
**AÃ§Ã£o:** Testar viabilidade de Electron+React, SwiftUI ou Tauri

**CritÃ©rio de decisÃ£o:** Qual permite prototipar mais rÃ¡pido

**Entrega:** DecisÃ£o documentada com justificativa

---

### Passo 2: Criar wireframe bÃ¡sico (< 1 dia)
**AÃ§Ã£o:** Desenhar interface simples com:
- Ãrea de input de prompt
- SeleÃ§Ã£o de LLMs (1-4)
- Ãrea de comparaÃ§Ã£o de respostas (lado a lado)
- BotÃ£o de seleÃ§Ã£o de melhor resposta
- VisualizaÃ§Ã£o de fluxo de validaÃ§Ã£o cruzada

**Entrega:** Wireframe visual (pode ser sketch simples)

---

### Passo 3: Implementar MVP (< 1 semana)
**AÃ§Ã£o:** Implementar funcionalidades core:
- Envio de prompt para mÃºltiplas LLMs
- ExibiÃ§Ã£o de respostas lado a lado
- SeleÃ§Ã£o de melhor resposta
- ValidaÃ§Ã£o cruzada automatizada
- PreservaÃ§Ã£o de contexto

**Entrega:** AplicaÃ§Ã£o funcional que passa nos 7 critÃ©rios de aceitaÃ§Ã£o

---

### Passo 4: Testar com casos reais (< 2 dias)
**AÃ§Ã£o:** Usar sistema para validar prompts reais e verificar se critÃ©rios sÃ£o satisfeitos

**Entrega:** RelatÃ³rio de testes com evidÃªncias (screenshots, logs)

---

### Passo 5: Iterar baseado em uso (contÃ­nuo)
**AÃ§Ã£o:** Ajustar UX/UI, performance e funcionalidades baseado em feedback real

**Entrega:** VersÃµes iterativas com melhorias documentadas

---

## âœ… VALIDAÃ‡ÃƒO (Definition of Done)

### V1 â€” CritÃ©rios de aceitaÃ§Ã£o passam
- [ ] Todos os 7 critÃ©rios de aceitaÃ§Ã£o foram testados e passaram

### V2 â€” Escopo respeitado
- [ ] Nenhuma funcionalidade fora do escopo foi implementada
- [ ] Todas as funcionalidades dentro do escopo foram implementadas

### V3 â€” Anti-resultados evitados
- [ ] Sistema Ã© transparente (usuÃ¡rio confia nas respostas)
- [ ] ComparaÃ§Ã£o ajuda a decidir (critÃ©rio de seleÃ§Ã£o claro)
- [ ] Processo nÃ£o Ã© complexo demais (usuÃ¡rio usa)
- [ ] ValidaÃ§Ã£o cruzada nÃ£o adiciona confusÃ£o
- [ ] NÃ£o hÃ¡ erro de orquestraÃ§Ã£o (fluxo funciona corretamente)

### V4 â€” Incertezas resolvidas dentro das fronteiras
- [ ] Stack foi escolhido baseado em teste rÃ¡pido (< 2 dias)
- [ ] UX/UI comeÃ§ou simples e iterou baseado em uso
- [ ] Custos sÃ£o alertados (nÃ£o controlados automaticamente)
- [ ] Performance foi testada com casos reais
- [ ] ConfiguraÃ§Ãµes usam JSON simples
- [ ] SeleÃ§Ã£o de melhor resposta Ã© manual
- [ ] Suporte para 4 LLMs (nÃ£o mais)

### V5 â€” DependÃªncias satisfeitas
- [ ] APIs de ChatGPT, Gemini, Manus e Claude estÃ£o integradas
- [ ] Sistema roda no macOS 12+
- [ ] ConexÃ£o com internet funciona

---

## ğŸš« O QUE NÃƒO FAZER

### âŒ NÃ£o implementar funcionalidades fora do escopo
**Exemplo:** NÃ£o criar versÃ£o Windows, nÃ£o adicionar mais de 4 LLMs, nÃ£o criar histÃ³rico persistente.

### âŒ NÃ£o gastar tempo excessivo em decisÃµes
**Exemplo:** NÃ£o gastar mais de 2 dias escolhendo stack, nÃ£o tentar criar interface "perfeita" antes de testar.

### âŒ NÃ£o ignorar anti-resultados
**Exemplo:** NÃ£o criar sistema que funciona mas ninguÃ©m usa, nÃ£o criar validaÃ§Ã£o cruzada que adiciona confusÃ£o.

### âŒ NÃ£o fingir que critÃ©rios passaram
**Exemplo:** NÃ£o marcar critÃ©rio como DONE sem testar, nÃ£o assumir que performance funciona sem testar.

---

## ğŸ“Š MÃ‰TRICAS DE SUCESSO

### M1 â€” Tempo de implementaÃ§Ã£o
**Objetivo:** MVP funcional em < 1 semana (apÃ³s escolha de stack)

### M2 â€” Taxa de validaÃ§Ã£o
**Objetivo:** 100% dos critÃ©rios de aceitaÃ§Ã£o passam nos testes

### M3 â€” Uso real
**Objetivo:** CEO usa o sistema para validar prompts reais em < 24h apÃ³s entrega

### M4 â€” ConfianÃ§a
**Objetivo:** CEO confia nas respostas e usa o sistema regularmente

---

## ğŸ¯ REGRA MÃƒE

**"Qualquer mudanÃ§a no resultado esperado deve gerar nova versÃ£o da ENDFIRST_SPEC e passar pelo ritual novamente."**

**Proibido:**
- Implementar funcionalidades fora do escopo sem atualizar a Spec
- Mudar resultado esperado sem versionar

**Permitido:**
- Resolver incertezas dentro das fronteiras definidas (OK se... / NÃƒO OK se...)
- Iterar UX/UI baseado em uso real (dentro do escopo)

---

## ğŸ“œ DECLARAÃ‡ÃƒO FINAL

Este prompt Ã© o **contrato de resultado** entre CEO e Cursor.

**GovernanÃ§a:** ENDFIRST_SPEC_EF-2026-001 (VALIDADA)

**PrÃ³ximo passo:** Implementar MVP que passa nos 7 critÃ©rios de aceitaÃ§Ã£o.

---

**VersÃ£o:** 1.0  
**Data:** 7 de Janeiro de 2026  
**Governado por:** ENDFIRST_SPEC_EF-2026-001  
**ReferÃªncia:** `/METODO/examples/ENDFIRST_SPEC_EF-2026-001_LLM_ORCHESTRATOR.md`
